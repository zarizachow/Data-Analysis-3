{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020ed968",
   "metadata": {},
   "source": [
    "# Building a prediction model on house prices\n",
    "Data Analysis 3 - Assignment 1  \n",
    "Submitted by: Zariza Chowdhury (ID: 2500086)    \n",
    "Deadline: 2 February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492fd56",
   "metadata": {},
   "source": [
    "## Business Case\n",
    "My business case is to operate a chain of Airbnbs.      \n",
    "The task is to build a pricing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed05f77",
   "metadata": {},
   "source": [
    "## Part I. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cad1b",
   "metadata": {},
   "source": [
    "### Step 0: Setup\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f7f81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Scikit-learn: models\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Scikit-learn: evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Interpretable ML\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beabdb6f",
   "metadata": {},
   "source": [
    "### Step 1: Data Selection, Wrangling and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e73ae9",
   "metadata": {},
   "source": [
    "##### A. Dataset Selection:\n",
    "- **Source**: Inside Airbnb - *https://insideairbnb.com/get-the-data/*\n",
    "- **Dataset**: *listings.csv* (loaded directly from GitHub Repo)\n",
    "- **City, Country**: Tokyo, Japan\n",
    "- **Time Period**: Q4 2024\n",
    "- **Reproducibility**: Data is uploaded and stored in a public GitHub repo and loaded directly via a raw URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c2803",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c7dbec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (21058, 75)\n",
      "\n",
      "Column names:\n",
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
      "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
      "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
      "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
      "       'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
      "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
      "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
      "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
      "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21058 entries, 0 to 21057\n",
      "Data columns (total 75 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            21058 non-null  int64  \n",
      " 1   listing_url                                   21058 non-null  object \n",
      " 2   scrape_id                                     21058 non-null  int64  \n",
      " 3   last_scraped                                  21058 non-null  object \n",
      " 4   source                                        21058 non-null  object \n",
      " 5   name                                          21058 non-null  object \n",
      " 6   description                                   20716 non-null  object \n",
      " 7   neighborhood_overview                         12731 non-null  object \n",
      " 8   picture_url                                   21058 non-null  object \n",
      " 9   host_id                                       21058 non-null  int64  \n",
      " 10  host_url                                      21058 non-null  object \n",
      " 11  host_name                                     21054 non-null  object \n",
      " 12  host_since                                    21054 non-null  object \n",
      " 13  host_location                                 15157 non-null  object \n",
      " 14  host_about                                    14759 non-null  object \n",
      " 15  host_response_time                            20578 non-null  object \n",
      " 16  host_response_rate                            20578 non-null  object \n",
      " 17  host_acceptance_rate                          20707 non-null  object \n",
      " 18  host_is_superhost                             19699 non-null  object \n",
      " 19  host_thumbnail_url                            21054 non-null  object \n",
      " 20  host_picture_url                              21054 non-null  object \n",
      " 21  host_neighbourhood                            6744 non-null   object \n",
      " 22  host_listings_count                           21054 non-null  float64\n",
      " 23  host_total_listings_count                     21054 non-null  float64\n",
      " 24  host_verifications                            21054 non-null  object \n",
      " 25  host_has_profile_pic                          21054 non-null  object \n",
      " 26  host_identity_verified                        21054 non-null  object \n",
      " 27  neighbourhood                                 12731 non-null  object \n",
      " 28  neighbourhood_cleansed                        21058 non-null  object \n",
      " 29  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 30  latitude                                      21058 non-null  float64\n",
      " 31  longitude                                     21058 non-null  float64\n",
      " 32  property_type                                 21058 non-null  object \n",
      " 33  room_type                                     21058 non-null  object \n",
      " 34  accommodates                                  21058 non-null  int64  \n",
      " 35  bathrooms                                     18831 non-null  float64\n",
      " 36  bathrooms_text                                21012 non-null  object \n",
      " 37  bedrooms                                      20794 non-null  float64\n",
      " 38  beds                                          18830 non-null  float64\n",
      " 39  amenities                                     21058 non-null  object \n",
      " 40  price                                         18799 non-null  object \n",
      " 41  minimum_nights                                21058 non-null  int64  \n",
      " 42  maximum_nights                                21058 non-null  int64  \n",
      " 43  minimum_minimum_nights                        21039 non-null  float64\n",
      " 44  maximum_minimum_nights                        21039 non-null  float64\n",
      " 45  minimum_maximum_nights                        21039 non-null  float64\n",
      " 46  maximum_maximum_nights                        21039 non-null  float64\n",
      " 47  minimum_nights_avg_ntm                        21039 non-null  float64\n",
      " 48  maximum_nights_avg_ntm                        21039 non-null  float64\n",
      " 49  calendar_updated                              0 non-null      float64\n",
      " 50  has_availability                              20963 non-null  object \n",
      " 51  availability_30                               21058 non-null  int64  \n",
      " 52  availability_60                               21058 non-null  int64  \n",
      " 53  availability_90                               21058 non-null  int64  \n",
      " 54  availability_365                              21058 non-null  int64  \n",
      " 55  calendar_last_scraped                         21058 non-null  object \n",
      " 56  number_of_reviews                             21058 non-null  int64  \n",
      " 57  number_of_reviews_ltm                         21058 non-null  int64  \n",
      " 58  number_of_reviews_l30d                        21058 non-null  int64  \n",
      " 59  first_review                                  18175 non-null  object \n",
      " 60  last_review                                   18175 non-null  object \n",
      " 61  review_scores_rating                          18175 non-null  float64\n",
      " 62  review_scores_accuracy                        18172 non-null  float64\n",
      " 63  review_scores_cleanliness                     18172 non-null  float64\n",
      " 64  review_scores_checkin                         18173 non-null  float64\n",
      " 65  review_scores_communication                   18172 non-null  float64\n",
      " 66  review_scores_location                        18172 non-null  float64\n",
      " 67  review_scores_value                           18172 non-null  float64\n",
      " 68  license                                       21041 non-null  object \n",
      " 69  instant_bookable                              21058 non-null  object \n",
      " 70  calculated_host_listings_count                21058 non-null  int64  \n",
      " 71  calculated_host_listings_count_entire_homes   21058 non-null  int64  \n",
      " 72  calculated_host_listings_count_private_rooms  21058 non-null  int64  \n",
      " 73  calculated_host_listings_count_shared_rooms   21058 non-null  int64  \n",
      " 74  reviews_per_month                             18175 non-null  float64\n",
      "dtypes: float64(23), int64(17), object(35)\n",
      "memory usage: 12.0+ MB\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197677</td>\n",
       "      <td>https://www.airbnb.com/rooms/197677</td>\n",
       "      <td>20241230011552</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Oshiage Holiday Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/38437056/d27f...</td>\n",
       "      <td>964081</td>\n",
       "      <td>...</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.80</td>\n",
       "      <td>M130003350</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>776070</td>\n",
       "      <td>https://www.airbnb.com/rooms/776070</td>\n",
       "      <td>20241230011552</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Kero-kero house room 1</td>\n",
       "      <td>We have been in airbnb since 2011 and it has g...</td>\n",
       "      <td>We love Nishinippori because is nearer to Toky...</td>\n",
       "      <td>https://a0.muscache.com/pictures/efd9f039-dbd2...</td>\n",
       "      <td>801494</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.92</td>\n",
       "      <td>M130000243</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905944</td>\n",
       "      <td>https://www.airbnb.com/rooms/905944</td>\n",
       "      <td>20241230011552</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>4F Spacious Apartment in Shinjuku / Shibuya Tokyo</td>\n",
       "      <td>NEWLY RENOVATED property entirely for you &amp; yo...</td>\n",
       "      <td>Hatagaya is a great neighborhood located 4 min...</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>4847803</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.78</td>\n",
       "      <td>Hotels and Inns Business Act | 渋谷区保健所長 | 31渋健生...</td>\n",
       "      <td>t</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016831</td>\n",
       "      <td>https://www.airbnb.com/rooms/1016831</td>\n",
       "      <td>20241230011552</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>5 mins Shibuya Cat modern sunny  Shimokita</td>\n",
       "      <td>Hi there, I am Wakana and I live with my two f...</td>\n",
       "      <td>The location is walkable distance to famous Sh...</td>\n",
       "      <td>https://a0.muscache.com/pictures/airflow/Hosti...</td>\n",
       "      <td>5596383</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.90</td>\n",
       "      <td>M130001107</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196177</td>\n",
       "      <td>https://www.airbnb.com/rooms/1196177</td>\n",
       "      <td>20241230011552</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Homestay at Host's House -  Senju-Ohashi Station</td>\n",
       "      <td>Our accommodation offers:  &lt;br /&gt;&lt;br /&gt;1. **Gr...</td>\n",
       "      <td>There are shopping mall near Senjuohashi stati...</td>\n",
       "      <td>https://a0.muscache.com/pictures/72890882/05ec...</td>\n",
       "      <td>5686404</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.82</td>\n",
       "      <td>M130007760</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           listing_url       scrape_id last_scraped  \\\n",
       "0   197677   https://www.airbnb.com/rooms/197677  20241230011552   2024-12-30   \n",
       "1   776070   https://www.airbnb.com/rooms/776070  20241230011552   2024-12-30   \n",
       "2   905944   https://www.airbnb.com/rooms/905944  20241230011552   2024-12-30   \n",
       "3  1016831  https://www.airbnb.com/rooms/1016831  20241230011552   2024-12-30   \n",
       "4  1196177  https://www.airbnb.com/rooms/1196177  20241230011552   2024-12-30   \n",
       "\n",
       "        source                                               name  \\\n",
       "0  city scrape                          Oshiage Holiday Apartment   \n",
       "1  city scrape                             Kero-kero house room 1   \n",
       "2  city scrape  4F Spacious Apartment in Shinjuku / Shibuya Tokyo   \n",
       "3  city scrape         5 mins Shibuya Cat modern sunny  Shimokita   \n",
       "4  city scrape   Homestay at Host's House -  Senju-Ohashi Station   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1  We have been in airbnb since 2011 and it has g...   \n",
       "2  NEWLY RENOVATED property entirely for you & yo...   \n",
       "3  Hi there, I am Wakana and I live with my two f...   \n",
       "4  Our accommodation offers:  <br /><br />1. **Gr...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0                                                NaN   \n",
       "1  We love Nishinippori because is nearer to Toky...   \n",
       "2  Hatagaya is a great neighborhood located 4 min...   \n",
       "3  The location is walkable distance to famous Sh...   \n",
       "4  There are shopping mall near Senjuohashi stati...   \n",
       "\n",
       "                                         picture_url  host_id  ...  \\\n",
       "0  https://a0.muscache.com/pictures/38437056/d27f...   964081  ...   \n",
       "1  https://a0.muscache.com/pictures/efd9f039-dbd2...   801494  ...   \n",
       "2  https://a0.muscache.com/pictures/miso/Hosting-...  4847803  ...   \n",
       "3  https://a0.muscache.com/pictures/airflow/Hosti...  5596383  ...   \n",
       "4  https://a0.muscache.com/pictures/72890882/05ec...  5686404  ...   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.84                   4.56                4.80   \n",
       "1                        4.98                   4.84                4.92   \n",
       "2                        4.91                   4.78                4.78   \n",
       "3                        4.98                   4.92                4.90   \n",
       "4                        4.92                   4.74                4.82   \n",
       "\n",
       "                                             license instant_bookable  \\\n",
       "0                                         M130003350                f   \n",
       "1                                         M130000243                f   \n",
       "2  Hotels and Inns Business Act | 渋谷区保健所長 | 31渋健生...                t   \n",
       "3                                         M130001107                f   \n",
       "4                                         M130007760                f   \n",
       "\n",
       "  calculated_host_listings_count calculated_host_listings_count_entire_homes  \\\n",
       "0                              1                                           1   \n",
       "1                              1                                           0   \n",
       "2                              8                                           8   \n",
       "3                              1                                           0   \n",
       "4                              1                                           0   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            1   \n",
       "2                                            0   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              1.13  \n",
       "1                                           0              1.79  \n",
       "2                                           0              1.69  \n",
       "3                                           0              1.90  \n",
       "4                                           0              0.97  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/zarizachow/Data-Analysis-3/refs/heads/main/Assignment-1/Data/Raw/Tokyo_listings/Tokyo_2024-30-Dec/listings.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Basic inspection\n",
    "print(\"Shape (rows, columns):\", df.shape)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f045dd",
   "metadata": {},
   "source": [
    "##### B. Data Wrangling and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a800e5",
   "metadata": {},
   "source": [
    "**Handle Missing Values**\n",
    "\n",
    "- Identify missing values across numeric and categorical variables - to ensure that all models can be estimated without errors\n",
    "- Impute numeric variables using simple summary statistics - this is a simple and robust method so the clean dataset is not sensitive to outliers\n",
    "- Treat missing categorical values as a separate category where needed - to preserve information and avoid dropping observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ad36d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group_cleansed    21058\n",
       "calendar_updated                21058\n",
       "minimum_nights_avg_ntm              0\n",
       "availability_365                    0\n",
       "availability_90                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing values\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Impute numeric variables with median\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Impute categorical variables with explicit category\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "# Sanity check\n",
    "df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149540d",
   "metadata": {},
   "source": [
    "**Clean and Standardize Numeric Variables**\n",
    "\n",
    "- Inspect numeric variables for unrealistic or extreme values – to identify potential data quality issues\n",
    "- Apply simple cleaning rules and transformations where needed – to ensure the variables are consistent\n",
    "- Standardize the format of the numeric variables – to support estimation across different predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7dbe36e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>7.505109e+17</td>\n",
       "      <td>5.214894e+17</td>\n",
       "      <td>8.998859e+06</td>\n",
       "      <td>4.632186e+07</td>\n",
       "      <td>9.859087e+17</td>\n",
       "      <td>1.188786e+18</td>\n",
       "      <td>1.313531e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrape_id</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.024123e+13</td>\n",
       "      <td>1.035962e+01</td>\n",
       "      <td>2.024123e+13</td>\n",
       "      <td>2.024123e+13</td>\n",
       "      <td>2.024123e+13</td>\n",
       "      <td>2.024123e+13</td>\n",
       "      <td>2.024123e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>3.326076e+08</td>\n",
       "      <td>1.985555e+08</td>\n",
       "      <td>6.648140e+06</td>\n",
       "      <td>1.542259e+08</td>\n",
       "      <td>3.303169e+08</td>\n",
       "      <td>5.272325e+08</td>\n",
       "      <td>6.619167e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.429951e+01</td>\n",
       "      <td>3.015113e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>1.410000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>3.146866e+01</td>\n",
       "      <td>4.109053e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>2.149100e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>3.569799e+01</td>\n",
       "      <td>4.157748e-02</td>\n",
       "      <td>3.555644e+01</td>\n",
       "      <td>3.568777e+01</td>\n",
       "      <td>3.570394e+01</td>\n",
       "      <td>3.572249e+01</td>\n",
       "      <td>3.577726e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.397380e+02</td>\n",
       "      <td>6.482399e-02</td>\n",
       "      <td>1.394746e+02</td>\n",
       "      <td>1.396993e+02</td>\n",
       "      <td>1.397276e+02</td>\n",
       "      <td>1.397923e+02</td>\n",
       "      <td>1.398767e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.436984e+00</td>\n",
       "      <td>2.955584e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.130331e+00</td>\n",
       "      <td>3.829521e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.391300e+00</td>\n",
       "      <td>9.099578e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.422357e+00</td>\n",
       "      <td>1.764815e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.665857e+04</td>\n",
       "      <td>1.966172e+04</td>\n",
       "      <td>4.786000e+03</td>\n",
       "      <td>1.491400e+04</td>\n",
       "      <td>2.085700e+04</td>\n",
       "      <td>3.142900e+04</td>\n",
       "      <td>1.170615e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.900893e+00</td>\n",
       "      <td>8.950705e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>3.715759e+02</td>\n",
       "      <td>2.966068e+02</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.800000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.590464e+00</td>\n",
       "      <td>8.838749e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>6.406306e+00</td>\n",
       "      <td>1.012232e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.994159e+02</td>\n",
       "      <td>3.947675e+02</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>5.476445e+02</td>\n",
       "      <td>3.974110e+02</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>5.224964e+00</td>\n",
       "      <td>8.943482e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>5.307076e+02</td>\n",
       "      <td>3.872895e+02</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>3.650000e+02</td>\n",
       "      <td>1.125000e+03</td>\n",
       "      <td>1.125000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_updated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_30</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.101862e+01</td>\n",
       "      <td>8.900239e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_60</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.699587e+01</td>\n",
       "      <td>1.827088e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.506672e+01</td>\n",
       "      <td>2.700001e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>6.800000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.602208e+02</td>\n",
       "      <td>1.007989e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>2.390000e+02</td>\n",
       "      <td>3.620000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>3.447754e+01</td>\n",
       "      <td>5.080225e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>2.740000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.342962e+01</td>\n",
       "      <td>1.459202e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>6.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.200019e+00</td>\n",
       "      <td>1.544107e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.721080e+00</td>\n",
       "      <td>2.726672e-01</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>4.630000e+00</td>\n",
       "      <td>4.780000e+00</td>\n",
       "      <td>4.900000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.761051e+00</td>\n",
       "      <td>2.534436e-01</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>4.690000e+00</td>\n",
       "      <td>4.820000e+00</td>\n",
       "      <td>4.920000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.708917e+00</td>\n",
       "      <td>2.999943e-01</td>\n",
       "      <td>3.380000e+00</td>\n",
       "      <td>4.610000e+00</td>\n",
       "      <td>4.780000e+00</td>\n",
       "      <td>4.910000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.790652e+00</td>\n",
       "      <td>2.386609e-01</td>\n",
       "      <td>3.670000e+00</td>\n",
       "      <td>4.730000e+00</td>\n",
       "      <td>4.860000e+00</td>\n",
       "      <td>4.940000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.840147e+00</td>\n",
       "      <td>1.952789e-01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.790000e+00</td>\n",
       "      <td>4.890000e+00</td>\n",
       "      <td>4.980000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.713690e+00</td>\n",
       "      <td>2.426903e-01</td>\n",
       "      <td>3.750000e+00</td>\n",
       "      <td>4.620000e+00</td>\n",
       "      <td>4.760000e+00</td>\n",
       "      <td>4.870000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.663266e+00</td>\n",
       "      <td>2.865243e-01</td>\n",
       "      <td>3.295600e+00</td>\n",
       "      <td>4.570000e+00</td>\n",
       "      <td>4.710000e+00</td>\n",
       "      <td>4.830000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>2.076522e+01</td>\n",
       "      <td>2.570133e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>1.200000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.856121e+01</td>\n",
       "      <td>2.502059e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.100000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.893057e+00</td>\n",
       "      <td>4.858423e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>4.378384e-02</td>\n",
       "      <td>3.388416e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>21058.0</td>\n",
       "      <td>1.676851e+00</td>\n",
       "      <td>1.171261e+00</td>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>8.900000e-01</td>\n",
       "      <td>1.430000e+00</td>\n",
       "      <td>2.210000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                count          mean  \\\n",
       "id                                            21058.0  7.505109e+17   \n",
       "scrape_id                                     21058.0  2.024123e+13   \n",
       "host_id                                       21058.0  3.326076e+08   \n",
       "host_listings_count                           21058.0  2.429951e+01   \n",
       "host_total_listings_count                     21058.0  3.146866e+01   \n",
       "neighbourhood_group_cleansed                      0.0           NaN   \n",
       "latitude                                      21058.0  3.569799e+01   \n",
       "longitude                                     21058.0  1.397380e+02   \n",
       "accommodates                                  21058.0  4.436984e+00   \n",
       "bathrooms                                     21058.0  1.130331e+00   \n",
       "bedrooms                                      21058.0  1.391300e+00   \n",
       "beds                                          21058.0  2.422357e+00   \n",
       "price                                         21058.0  2.665857e+04   \n",
       "minimum_nights                                21058.0  4.900893e+00   \n",
       "maximum_nights                                21058.0  3.715759e+02   \n",
       "minimum_minimum_nights                        21058.0  4.590464e+00   \n",
       "maximum_minimum_nights                        21058.0  6.406306e+00   \n",
       "minimum_maximum_nights                        21058.0  4.994159e+02   \n",
       "maximum_maximum_nights                        21058.0  5.476445e+02   \n",
       "minimum_nights_avg_ntm                        21058.0  5.224964e+00   \n",
       "maximum_nights_avg_ntm                        21058.0  5.307076e+02   \n",
       "calendar_updated                                  0.0           NaN   \n",
       "availability_30                               21058.0  1.101862e+01   \n",
       "availability_60                               21058.0  2.699587e+01   \n",
       "availability_90                               21058.0  4.506672e+01   \n",
       "availability_365                              21058.0  1.602208e+02   \n",
       "number_of_reviews                             21058.0  3.447754e+01   \n",
       "number_of_reviews_ltm                         21058.0  1.342962e+01   \n",
       "number_of_reviews_l30d                        21058.0  1.200019e+00   \n",
       "review_scores_rating                          21058.0  4.721080e+00   \n",
       "review_scores_accuracy                        21058.0  4.761051e+00   \n",
       "review_scores_cleanliness                     21058.0  4.708917e+00   \n",
       "review_scores_checkin                         21058.0  4.790652e+00   \n",
       "review_scores_communication                   21058.0  4.840147e+00   \n",
       "review_scores_location                        21058.0  4.713690e+00   \n",
       "review_scores_value                           21058.0  4.663266e+00   \n",
       "calculated_host_listings_count                21058.0  2.076522e+01   \n",
       "calculated_host_listings_count_entire_homes   21058.0  1.856121e+01   \n",
       "calculated_host_listings_count_private_rooms  21058.0  1.893057e+00   \n",
       "calculated_host_listings_count_shared_rooms   21058.0  4.378384e-02   \n",
       "reviews_per_month                             21058.0  1.676851e+00   \n",
       "\n",
       "                                                       std           min  \\\n",
       "id                                            5.214894e+17  8.998859e+06   \n",
       "scrape_id                                     1.035962e+01  2.024123e+13   \n",
       "host_id                                       1.985555e+08  6.648140e+06   \n",
       "host_listings_count                           3.015113e+01  1.000000e+00   \n",
       "host_total_listings_count                     4.109053e+01  1.000000e+00   \n",
       "neighbourhood_group_cleansed                           NaN           NaN   \n",
       "latitude                                      4.157748e-02  3.555644e+01   \n",
       "longitude                                     6.482399e-02  1.394746e+02   \n",
       "accommodates                                  2.955584e+00  1.000000e+00   \n",
       "bathrooms                                     3.829521e-01  5.000000e-01   \n",
       "bedrooms                                      9.099578e-01  0.000000e+00   \n",
       "beds                                          1.764815e+00  0.000000e+00   \n",
       "price                                         1.966172e+04  4.786000e+03   \n",
       "minimum_nights                                8.950705e+00  1.000000e+00   \n",
       "maximum_nights                                2.966068e+02  1.000000e+01   \n",
       "minimum_minimum_nights                        8.838749e+00  1.000000e+00   \n",
       "maximum_minimum_nights                        1.012232e+01  1.000000e+00   \n",
       "minimum_maximum_nights                        3.947675e+02  7.000000e+00   \n",
       "maximum_maximum_nights                        3.974110e+02  1.400000e+01   \n",
       "minimum_nights_avg_ntm                        8.943482e+00  1.000000e+00   \n",
       "maximum_nights_avg_ntm                        3.872895e+02  1.400000e+01   \n",
       "calendar_updated                                       NaN           NaN   \n",
       "availability_30                               8.900239e+00  0.000000e+00   \n",
       "availability_60                               1.827088e+01  0.000000e+00   \n",
       "availability_90                               2.700001e+01  0.000000e+00   \n",
       "availability_365                              1.007989e+02  0.000000e+00   \n",
       "number_of_reviews                             5.080225e+01  0.000000e+00   \n",
       "number_of_reviews_ltm                         1.459202e+01  0.000000e+00   \n",
       "number_of_reviews_l30d                        1.544107e+00  0.000000e+00   \n",
       "review_scores_rating                          2.726672e-01  3.500000e+00   \n",
       "review_scores_accuracy                        2.534436e-01  3.500000e+00   \n",
       "review_scores_cleanliness                     2.999943e-01  3.380000e+00   \n",
       "review_scores_checkin                         2.386609e-01  3.670000e+00   \n",
       "review_scores_communication                   1.952789e-01  4.000000e+00   \n",
       "review_scores_location                        2.426903e-01  3.750000e+00   \n",
       "review_scores_value                           2.865243e-01  3.295600e+00   \n",
       "calculated_host_listings_count                2.570133e+01  1.000000e+00   \n",
       "calculated_host_listings_count_entire_homes   2.502059e+01  0.000000e+00   \n",
       "calculated_host_listings_count_private_rooms  4.858423e+00  0.000000e+00   \n",
       "calculated_host_listings_count_shared_rooms   3.388416e-01  0.000000e+00   \n",
       "reviews_per_month                             1.171261e+00  6.000000e-02   \n",
       "\n",
       "                                                       25%           50%  \\\n",
       "id                                            4.632186e+07  9.859087e+17   \n",
       "scrape_id                                     2.024123e+13  2.024123e+13   \n",
       "host_id                                       1.542259e+08  3.303169e+08   \n",
       "host_listings_count                           4.000000e+00  1.100000e+01   \n",
       "host_total_listings_count                     6.000000e+00  1.500000e+01   \n",
       "neighbourhood_group_cleansed                           NaN           NaN   \n",
       "latitude                                      3.568777e+01  3.570394e+01   \n",
       "longitude                                     1.396993e+02  1.397276e+02   \n",
       "accommodates                                  2.000000e+00  4.000000e+00   \n",
       "bathrooms                                     1.000000e+00  1.000000e+00   \n",
       "bedrooms                                      1.000000e+00  1.000000e+00   \n",
       "beds                                          1.000000e+00  2.000000e+00   \n",
       "price                                         1.491400e+04  2.085700e+04   \n",
       "minimum_nights                                1.000000e+00  2.000000e+00   \n",
       "maximum_nights                                1.800000e+02  3.650000e+02   \n",
       "minimum_minimum_nights                        1.000000e+00  1.000000e+00   \n",
       "maximum_minimum_nights                        1.000000e+00  2.000000e+00   \n",
       "minimum_maximum_nights                        3.650000e+02  3.650000e+02   \n",
       "maximum_maximum_nights                        3.650000e+02  3.650000e+02   \n",
       "minimum_nights_avg_ntm                        1.000000e+00  2.000000e+00   \n",
       "maximum_nights_avg_ntm                        3.650000e+02  3.650000e+02   \n",
       "calendar_updated                                       NaN           NaN   \n",
       "availability_30                               3.000000e+00  9.000000e+00   \n",
       "availability_60                               1.200000e+01  2.600000e+01   \n",
       "availability_90                               2.400000e+01  4.600000e+01   \n",
       "availability_365                              8.300000e+01  1.480000e+02   \n",
       "number_of_reviews                             3.000000e+00  1.500000e+01   \n",
       "number_of_reviews_ltm                         2.000000e+00  9.000000e+00   \n",
       "number_of_reviews_l30d                        0.000000e+00  1.000000e+00   \n",
       "review_scores_rating                          4.630000e+00  4.780000e+00   \n",
       "review_scores_accuracy                        4.690000e+00  4.820000e+00   \n",
       "review_scores_cleanliness                     4.610000e+00  4.780000e+00   \n",
       "review_scores_checkin                         4.730000e+00  4.860000e+00   \n",
       "review_scores_communication                   4.790000e+00  4.890000e+00   \n",
       "review_scores_location                        4.620000e+00  4.760000e+00   \n",
       "review_scores_value                           4.570000e+00  4.710000e+00   \n",
       "calculated_host_listings_count                4.000000e+00  1.000000e+01   \n",
       "calculated_host_listings_count_entire_homes   2.000000e+00  8.000000e+00   \n",
       "calculated_host_listings_count_private_rooms  0.000000e+00  0.000000e+00   \n",
       "calculated_host_listings_count_shared_rooms   0.000000e+00  0.000000e+00   \n",
       "reviews_per_month                             8.900000e-01  1.430000e+00   \n",
       "\n",
       "                                                       75%           max  \n",
       "id                                            1.188786e+18  1.313531e+18  \n",
       "scrape_id                                     2.024123e+13  2.024123e+13  \n",
       "host_id                                       5.272325e+08  6.619167e+08  \n",
       "host_listings_count                           3.200000e+01  1.410000e+02  \n",
       "host_total_listings_count                     3.900000e+01  2.149100e+02  \n",
       "neighbourhood_group_cleansed                           NaN           NaN  \n",
       "latitude                                      3.572249e+01  3.577726e+01  \n",
       "longitude                                     1.397923e+02  1.398767e+02  \n",
       "accommodates                                  6.000000e+00  1.600000e+01  \n",
       "bathrooms                                     1.000000e+00  3.000000e+00  \n",
       "bedrooms                                      2.000000e+00  5.000000e+00  \n",
       "beds                                          3.000000e+00  1.000000e+01  \n",
       "price                                         3.142900e+04  1.170615e+05  \n",
       "minimum_nights                                2.000000e+00  3.000000e+01  \n",
       "maximum_nights                                3.650000e+02  1.125000e+03  \n",
       "minimum_minimum_nights                        2.000000e+00  3.000000e+01  \n",
       "maximum_minimum_nights                        4.000000e+00  3.000000e+01  \n",
       "minimum_maximum_nights                        1.125000e+03  1.125000e+03  \n",
       "maximum_maximum_nights                        1.125000e+03  1.125000e+03  \n",
       "minimum_nights_avg_ntm                        3.000000e+00  3.000000e+01  \n",
       "maximum_nights_avg_ntm                        1.125000e+03  1.125000e+03  \n",
       "calendar_updated                                       NaN           NaN  \n",
       "availability_30                               1.800000e+01  3.000000e+01  \n",
       "availability_60                               4.200000e+01  6.000000e+01  \n",
       "availability_90                               6.800000e+01  8.900000e+01  \n",
       "availability_365                              2.390000e+02  3.620000e+02  \n",
       "number_of_reviews                             4.200000e+01  2.740000e+02  \n",
       "number_of_reviews_ltm                         2.000000e+01  6.600000e+01  \n",
       "number_of_reviews_l30d                        2.000000e+00  7.000000e+00  \n",
       "review_scores_rating                          4.900000e+00  5.000000e+00  \n",
       "review_scores_accuracy                        4.920000e+00  5.000000e+00  \n",
       "review_scores_cleanliness                     4.910000e+00  5.000000e+00  \n",
       "review_scores_checkin                         4.940000e+00  5.000000e+00  \n",
       "review_scores_communication                   4.980000e+00  5.000000e+00  \n",
       "review_scores_location                        4.870000e+00  5.000000e+00  \n",
       "review_scores_value                           4.830000e+00  5.000000e+00  \n",
       "calculated_host_listings_count                2.700000e+01  1.200000e+02  \n",
       "calculated_host_listings_count_entire_homes   2.400000e+01  1.100000e+02  \n",
       "calculated_host_listings_count_private_rooms  1.000000e+00  3.100000e+01  \n",
       "calculated_host_listings_count_shared_rooms   0.000000e+00  3.000000e+00  \n",
       "reviews_per_month                             2.210000e+00  6.000000e+00  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and standardize numeric variables\n",
    "\n",
    "# Fix price variable (it may contain strings or missing)\n",
    "df[\"price\"] = df[\"price\"].replace(\"missing\", np.nan)\n",
    "\n",
    "df[\"price\"] = (\n",
    "    df[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Impute missing price values with median\n",
    "df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n",
    "\n",
    "# Update numeric columns after cleaning price\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Inspect summary statistics\n",
    "df[numeric_cols].describe().T\n",
    "\n",
    "# Cap extreme values (simple winsorization)\n",
    "for col in numeric_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = df[col].clip(lower, upper)\n",
    "\n",
    "# Sanity check after cleaning\n",
    "df[numeric_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c680ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), np.int64(0), (21058, 75))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure target variable (price) is numeric (avoid errors in models)\n",
    "\n",
    "df[\"price\"] = (\n",
    "    df[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where price is missing\n",
    "df = df.dropna(subset=[\"price\"])\n",
    "\n",
    "# Sanity check\n",
    "df[\"price\"].dtype, df[\"price\"].isna().sum(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3580779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['neighbourhood_group_cleansed', 'calendar_updated', 'scrape_id']\n",
      "New shape: (21058, 72)\n"
     ]
    }
   ],
   "source": [
    "# Drop unusable variables (except id)\n",
    "\n",
    "# Columns with all missing values\n",
    "all_missing_cols = [\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \"calendar_updated\"\n",
    "]\n",
    "\n",
    "# System-generated id columns\n",
    "id_cols = [\n",
    "    \"scrape_id\"\n",
    "]\n",
    "\n",
    "cols_to_drop = [col for col in all_missing_cols + id_cols if col in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Sanity check\n",
    "print(\"Dropped columns:\", cols_to_drop)\n",
    "print(\"New shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00ab92",
   "metadata": {},
   "source": [
    "**Variable Selection for Modelling**\n",
    "\n",
    "- Exclude id, URLs, dates, and free-text fields that are not useful for prediction  \n",
    "- Keep structured listing, host, location, and amenity variables  \n",
    "- Use the same variables across all datasets for out-of-sample comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6908f3",
   "metadata": {},
   "source": [
    "**Extract Amenities**\n",
    "\n",
    "- Parse the amenities text field into structured variables – to make the data usable  \n",
    "- Create binary indicators for selected amenities – to capture key listing features  \n",
    "- Use amenity features as additional inputs in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d84bce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenity_wifi</th>\n",
       "      <th>amenity_kitchen</th>\n",
       "      <th>amenity_air_conditioning</th>\n",
       "      <th>amenity_heating</th>\n",
       "      <th>amenity_washer</th>\n",
       "      <th>amenity_dryer</th>\n",
       "      <th>amenity_elevator</th>\n",
       "      <th>amenity_tv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amenity_wifi  amenity_kitchen  amenity_air_conditioning  amenity_heating  \\\n",
       "0             1                1                         1                1   \n",
       "1             1                0                         1                1   \n",
       "2             1                1                         0                1   \n",
       "3             1                1                         0                1   \n",
       "4             1                0                         0                1   \n",
       "\n",
       "   amenity_washer  amenity_dryer  amenity_elevator  amenity_tv  \n",
       "0               1              1                 0           1  \n",
       "1               0              1                 0           1  \n",
       "2               0              1                 0           1  \n",
       "3               1              1                 0           1  \n",
       "4               1              1                 0           1  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract amenities\n",
    "\n",
    "# Convert amenities column to string\n",
    "df[\"amenities\"] = df[\"amenities\"].astype(str)\n",
    "\n",
    "# List of selected amenities to extract\n",
    "amenities_list = [\n",
    "    \"Wifi\",\n",
    "    \"Kitchen\",\n",
    "    \"Air conditioning\",\n",
    "    \"Heating\",\n",
    "    \"Washer\",\n",
    "    \"Dryer\",\n",
    "    \"Elevator\",\n",
    "    \"TV\"\n",
    "]\n",
    "\n",
    "# Create binary indicators for each amenity\n",
    "for amenity in amenities_list:\n",
    "    df[f\"amenity_{amenity.lower().replace(' ', '_')}\"] = (\n",
    "        df[\"amenities\"].str.contains(amenity, case=False, regex=False).astype(int)\n",
    "    )\n",
    "\n",
    "# Drop original amenities text field\n",
    "df = df.drop(columns=[\"amenities\"])\n",
    "\n",
    "# Sanity check\n",
    "df.filter(like=\"amenity_\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7413b9",
   "metadata": {},
   "source": [
    "**Save Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved (overwritten if existed):\n",
      "Data/Cleaned/Tokyo_listings/tokyo_listings_q4_2024_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned Tokyo Q4 2024 dataset\n",
    "\n",
    "output_path = \"Data/Cleaned/Tokyo_listings/tokyo_listings_q4_2024_clean.csv\"\n",
    "\n",
    "# Overwrite file if it already exists\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved (overwrite if existed):\")\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8feeea",
   "metadata": {},
   "source": [
    "**Encode Categorical Variables**\n",
    "\n",
    "- Select relevant categorical variables  \n",
    "- Convert categorical variables into numeric form  \n",
    "- Use the same encoding across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listing_url',\n",
       " 'last_scraped',\n",
       " 'source',\n",
       " 'name',\n",
       " 'description',\n",
       " 'neighborhood_overview',\n",
       " 'picture_url',\n",
       " 'host_url',\n",
       " 'host_name',\n",
       " 'host_since',\n",
       " 'host_location',\n",
       " 'host_about',\n",
       " 'host_response_time',\n",
       " 'host_response_rate',\n",
       " 'host_acceptance_rate',\n",
       " 'host_is_superhost',\n",
       " 'host_thumbnail_url',\n",
       " 'host_picture_url',\n",
       " 'host_neighbourhood',\n",
       " 'host_verifications',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'neighbourhood',\n",
       " 'neighbourhood_cleansed',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'bathrooms_text',\n",
       " 'has_availability',\n",
       " 'calendar_last_scraped',\n",
       " 'first_review',\n",
       " 'last_review',\n",
       " 'license',\n",
       " 'instant_bookable']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "# Select categorical variables\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Exclude variables not used for modelling\n",
    "categorical_cols = [\n",
    "    col for col in categorical_cols\n",
    "    if col not in [\"id\"]  # keep id as primary key, but not as a feature\n",
    "]\n",
    "\n",
    "# Sanity check\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85c436",
   "metadata": {},
   "source": [
    "### Step 2: Build Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cde5b2",
   "metadata": {},
   "source": [
    "##### A. OLS Model\n",
    "\n",
    "- Define target variable (`price`) and feature matrix (`X`)  \n",
    "- Split data into training and test sets  \n",
    "- Fit an OLS baseline model and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "74931b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Model RMSE: 12740.712267742509\n"
     ]
    }
   ],
   "source": [
    "# OLS model (with imputation in pipeline)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define target and features\n",
    "y = df[\"price\"]\n",
    "X = df.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OLS pipeline\n",
    "ols_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "ols_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ols = ols_model.predict(X_test)\n",
    "\n",
    "# Evaluation (RMSE)\n",
    "rmse_ols = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "print(\"OLS Model RMSE:\", rmse_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fd2fc",
   "metadata": {},
   "source": [
    "##### B. LASSO Model\n",
    "\n",
    "- Use the same target variable and feature set as in the OLS model  \n",
    "- Fit a LASSO model to allow coefficient shrinkage  \n",
    "- Predict prices on the test set and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e2846df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables kept: ['room_type', 'property_type', 'neighbourhood_cleansed', 'host_is_superhost', 'instant_bookable']\n",
      "Number of object/string columns dropped: 28\n",
      "Final feature shape: (21058, 49)\n"
     ]
    }
   ],
   "source": [
    "# Restrict categorical variables before LASSO to avoid huge dummy matrix\n",
    "\n",
    "# Define categorical variables to keep (class-style)\n",
    "categorical_keep = [\n",
    "    \"room_type\",\n",
    "    \"property_type\",\n",
    "    \"neighbourhood_cleansed\",\n",
    "    \"host_is_superhost\",\n",
    "    \"instant_bookable\"\n",
    "]\n",
    "\n",
    "# Keep only those that exist in the dataset\n",
    "categorical_keep = [c for c in categorical_keep if c in df.columns]\n",
    "\n",
    "# Define target and features\n",
    "y = df[\"price\"]\n",
    "X = df.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Drop all other object/string columns\n",
    "object_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in object_cols if c not in categorical_keep]\n",
    "\n",
    "X = X.drop(columns=drop_cols)\n",
    "\n",
    "# Sanity check\n",
    "print(\"Categorical variables kept:\", categorical_keep)\n",
    "print(\"Number of object/string columns dropped:\", len(drop_cols))\n",
    "print(\"Final feature shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ee0c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Model RMSE: 15064.244563773585\n"
     ]
    }
   ],
   "source": [
    "# LASSO model\n",
    "\n",
    "# Train-test split (using the restricted X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_lasso = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LASSO pipeline\n",
    "lasso_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_lasso),\n",
    "        (\"model\", Lasso(alpha=1.0, max_iter=3000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluation (RMSE)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "print(\"LASSO Model RMSE:\", rmse_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c2cb8",
   "metadata": {},
   "source": [
    "##### C. Random Forest Model\n",
    "\n",
    "- Use the same target variable and working feature set (`X`, `y`)  \n",
    "- Fit a Random Forest model and generate predictions  \n",
    "- Evaluate performance on the test set (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b4702b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model RMSE: 13867.28701676302\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model\n",
    "\n",
    "# Train-test split (using the same working X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest pipeline (final, faster spec)\n",
    "rf_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_rf),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation (RMSE)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest Model RMSE:\", rmse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c182e6f",
   "metadata": {},
   "source": [
    "##### D. Boosting Model (Gradient Boosting)\n",
    "\n",
    "- **Chosen model**: Gradient Boosting\n",
    "- **Reason for choosing this model**: This is common boosting method used in class that performs well on tabular data and allows feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "46929b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model RMSE: 14187.44720172246\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting model\n",
    "\n",
    "# Train-test split (using the same working X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing (same as Random Forest)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Gradient Boosting pipeline\n",
    "gb_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_gb),\n",
    "        (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluation (RMSE)\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "print(\"Gradient Boosting Model RMSE:\", rmse_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabde36e",
   "metadata": {},
   "source": [
    "##### E. Decision Tree\n",
    "\n",
    "- **Chosen model**: Decision Tree (CART)  \n",
    "- **Reason for choosing the model**: This is a simple tree-based model which provides a clear baseline to compare with ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "465c6740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model RMSE: 18161.323384531686\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model (CART)\n",
    "\n",
    "# Train-test split (using the same working X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing (same as RF and Boosting)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_dt = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Decision Tree pipeline\n",
    "dt_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_dt),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluation (RMSE)\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Model RMSE:\", rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b706d3",
   "metadata": {},
   "source": [
    "### Step 3: Compare the Models in Terms of Fit and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c343d",
   "metadata": {},
   "source": [
    "##### A. Horserace Table\n",
    "\n",
    "The horserace table compares the 5 models in terms of predictive accuracy and computation time.\n",
    "\n",
    "- **RMSE** is used to measure out-of-sample prediction error. Lower RMSE values indicate better predictive performance.\n",
    "- **Time** captures total model training and prediction time\n",
    "- All models use the same data and train–test split\n",
    "- This ensures results are directly comparable across models\n",
    "\n",
    "| Model                    | RMSE (Test Set) | Runtime (seconds) |\n",
    "|--------------------------|----------------|-------------------|\n",
    "| OLS                      | 12,740.71      | 4.5               |\n",
    "| LASSO                    | 15,064.24      | 1.7               |\n",
    "| Random Forest            | 13,867.29      | 0.9               |\n",
    "| Gradient Boosting        | 14,187.45      | 10.3              |\n",
    "| Decision Tree (CART)     | 18,161.32      | 0.8               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf344d3",
   "metadata": {},
   "source": [
    "##### B. Discussion of Performance\n",
    "\n",
    "The horserace table shows clear differences across the models in terms of fit and runtime.\n",
    "\n",
    "- **OLS**  \n",
    "  OLS performs well for a simple baseline model, with a relatively low RMSE and low runtime.\n",
    "\n",
    "- **LASSO**  \n",
    "  LASSO performs worse than OLS, suggesting that shrinkage/regularisation does not improve prediction in this setup.\n",
    "\n",
    "- **Random Forest**  \n",
    "  Random Forest performs better than LASSO and the single tree, but it is not the best model here. It is also more computationally expensive than OLS.\n",
    "\n",
    "- **Gradient Boosting**  \n",
    "  Gradient Boosting performs similarly to Random Forest and improves over a single decision tree, but it does not beat the simpler OLS baseline in this case.\n",
    "\n",
    "- **Decision Tree (CART)**  \n",
    "  CART performs the worst, which is expected because a single tree can overfit and does not generalize as well as ensemble models.\n",
    "\n",
    "Overall, the results show that more complex models do not automatically guarantee better accuracy.  \n",
    "In this dataset, OLS provides a strong and efficient baseline, while tree-based models add complexity with limited gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d071228",
   "metadata": {},
   "source": [
    "### Step 4: Analyzing Random Forest Model and Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b08468",
   "metadata": {},
   "source": [
    "##### A. Feature Importance of Random Forest\n",
    "- Feature importance shows which variables contribute most to predicting prices in this model\n",
    "- Since this is a black-box model without an interpretable formula, feature importance helps interpret its behaviour\n",
    "- Feature importance values are based on how much each feature improves prediction across the trees\n",
    "- The focus is to identify the most important features, not the exact numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "59872726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>0.171820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beds</td>\n",
       "      <td>0.118331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.085578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.055443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.033426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.027054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>property_type_Entire home</td>\n",
       "      <td>0.025415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_id</td>\n",
       "      <td>0.023638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>availability_90</td>\n",
       "      <td>0.021210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>calculated_host_listings_count_entire_homes</td>\n",
       "      <td>0.020079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         feature  importance\n",
       "5                                   accommodates    0.171820\n",
       "8                                           beds    0.118331\n",
       "7                                       bedrooms    0.085578\n",
       "6                                      bathrooms    0.055443\n",
       "3                                       latitude    0.033426\n",
       "4                                      longitude    0.027054\n",
       "104                    property_type_Entire home    0.025415\n",
       "0                                        host_id    0.023638\n",
       "19                               availability_90    0.021210\n",
       "32   calculated_host_listings_count_entire_homes    0.020079"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Feature Importance\n",
    "\n",
    "# Get fitted Random Forest model\n",
    "rf_estimator = rf_model.named_steps[\"model\"]\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "preprocessor = rf_model.named_steps[\"preprocessor\"]\n",
    "\n",
    "# Numeric feature names\n",
    "num_features = preprocessor.named_transformers_[\"num\"].feature_names_in_\n",
    "\n",
    "# Categorical feature names (after one-hot encoding)\n",
    "cat_ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_features = cat_ohe.get_feature_names_out(\n",
    "    preprocessor.named_transformers_[\"cat\"].feature_names_in_\n",
    ")\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "# Extract feature importances\n",
    "importances = rf_estimator.feature_importances_\n",
    "\n",
    "# Create importance table\n",
    "rf_importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "# Show top 10 features\n",
    "rf_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f673a3",
   "metadata": {},
   "source": [
    "**Top 10 Features – Random Forest**\n",
    "\n",
    "| Feature                          | Importance |\n",
    "|----------------------------------|------------|\n",
    "| accommodates                      | 0.171820   |\n",
    "| beds                              | 0.118331   |\n",
    "| bedrooms                          | 0.085578   |\n",
    "| bathrooms                         | 0.055443   |\n",
    "| latitude                          | 0.033426   |\n",
    "| longitude                         | 0.027054   |\n",
    "| property_type_Entire home         | 0.025415   |\n",
    "| host_id                           | 0.023638   |\n",
    "| availability_90                   | 0.021210   |\n",
    "| calculated_host_listings_count_entire_homes | 0.020079   |\n",
    "\n",
    "The Random Forest model is mainly driven by **capacity** (`accommodates`) and **property size** (`beds`, `bedrooms`, `bathrooms`).  \n",
    "**Location** (`latitude`, `longitude`) and **property type** (`property_type_Entire home`) also matter for predicting price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b3e38",
   "metadata": {},
   "source": [
    "##### B. Feature Importance of Gradient Boosting\n",
    "\n",
    "This section examines which features are most important in the Gradient Boosting model.\n",
    "\n",
    "- Feature importance highlights which variables drive price predictions\n",
    "- Gradient Boosting is also a black-box model, so feature importance helps with interpretation\n",
    "- Importance values reflect how much each feature contributes to improving predictions\n",
    "- The focus is on identifying the most important features rather than exact numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6e7fd607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>0.516623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beds</td>\n",
       "      <td>0.090508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.063380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.061143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.052976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.029512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>neighbourhood_cleansed_Shinjuku Ku</td>\n",
       "      <td>0.019219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>availability_90</td>\n",
       "      <td>0.018191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_id</td>\n",
       "      <td>0.013844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>neighbourhood_cleansed_Shibuya Ku</td>\n",
       "      <td>0.010434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature  importance\n",
       "5                         accommodates    0.516623\n",
       "8                                 beds    0.090508\n",
       "6                            bathrooms    0.063380\n",
       "3                             latitude    0.061143\n",
       "7                             bedrooms    0.052976\n",
       "4                            longitude    0.029512\n",
       "88  neighbourhood_cleansed_Shinjuku Ku    0.019219\n",
       "19                     availability_90    0.018191\n",
       "0                              host_id    0.013844\n",
       "86   neighbourhood_cleansed_Shibuya Ku    0.010434"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Feature Importance\n",
    "\n",
    "# Get fitted Gradient Boosting model\n",
    "gb_estimator = gb_model.named_steps[\"model\"]\n",
    "\n",
    "# Get preprocessor\n",
    "preprocessor = gb_model.named_steps[\"preprocessor\"]\n",
    "\n",
    "# Numeric feature names\n",
    "num_features = preprocessor.named_transformers_[\"num\"].feature_names_in_\n",
    "\n",
    "# Categorical feature names (after one-hot encoding)\n",
    "cat_ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_features = cat_ohe.get_feature_names_out(\n",
    "    preprocessor.named_transformers_[\"cat\"].feature_names_in_\n",
    ")\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "# Extract feature importances\n",
    "importances = gb_estimator.feature_importances_\n",
    "\n",
    "# Create importance table\n",
    "gb_importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "# Show top 10 features\n",
    "gb_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99a169",
   "metadata": {},
   "source": [
    "**Top 10 Features – Gradient Boosting**\n",
    "\n",
    "| Feature                                | Importance |\n",
    "|----------------------------------------|------------|\n",
    "| accommodates                           | 0.516623   |\n",
    "| beds                                   | 0.090508   |\n",
    "| bathrooms                              | 0.063380   |\n",
    "| latitude                               | 0.061143   |\n",
    "| bedrooms                               | 0.052976   |\n",
    "| longitude                              | 0.029512   |\n",
    "| neighbourhood_cleansed_Shinjuku Ku     | 0.019219   |\n",
    "| availability_90                        | 0.018191   |\n",
    "| host_id                                | 0.013844   |\n",
    "| neighbourhood_cleansed_Shibuya Ku      | 0.010434   |\n",
    "\n",
    "The Gradient Boosting model is mainly driven by capacity (`accommodates`) and property size (`beds`, `bathrooms`, `bedrooms`).      \n",
    "Location (`latitude`, `longitude`, and neighbourhood) and availability also contribute to price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a63db16",
   "metadata": {},
   "source": [
    "##### C. Compare the 10 Most Important Features of Random Forest and Gradient Boosting Models\n",
    "\n",
    "Both models rely on similar core drivers of price, but they emphasize different aspects of the listing.\n",
    "\n",
    "**Similarities: Features appearing in the top 10 of both models**\n",
    "- Capacity: `accommodates`\n",
    "- Property size: `beds`, `bathrooms`, `bedrooms`\n",
    "- Location: `latitude`, `longitude`\n",
    "- Availability: `availability_90`\n",
    "- Host-related: `host_id`\n",
    "\n",
    "**Differences**\n",
    "- **Random Forest** places more weight on host portfolio size and listing structure, such as  \n",
    "  `property_type_Entire home` and `calculated_host_listings_count_entire_homes`.\n",
    "- **Gradient Boosting** gives more importance to neighbourhood-specific variables, such as  \n",
    "  `neighbourhood_cleansed_Shinjuku Ku` and `neighbourhood_cleansed_Shibuya Ku`.\n",
    "\n",
    "Overall, both models confirm that **capacity and location** are the main drivers of Airbnb prices.  \n",
    "However, Gradient Boosting captures neighbourhood effects more strongly, while Random Forest focuses more on host and property structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed488613",
   "metadata": {},
   "source": [
    "## Part II. Validity\n",
    "\n",
    "This section tests how well the models perform on new/'live' datasets.\n",
    "\n",
    "2 additional datasets are used:\n",
    "- A **later time period** for the same city (Tokyo) - `Q3 2025`\n",
    "- A **different city** from the same region - \n",
    "\n",
    "The same data wrangling steps and the same 5 predictive models from Part I are applied to these new datasets.       \n",
    "Model performance is then compared to assess how well the models generalize to new data and settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6be38d",
   "metadata": {},
   "source": [
    "### Step 5: Adding 2 'Live' Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721c8e0",
   "metadata": {},
   "source": [
    "##### A. Later Date: Tokyo (Q3 2025)\n",
    "\n",
    "- **City, Country**: Tokyo, Japan  \n",
    "- **Dataset**: *listings.csv* (loaded directly from GitHub Repo)\n",
    "- **Time Period**: Q3 2025  \n",
    "- **Purpose**: Evaluate how well models trained on earlier data perform on a later time period\n",
    "\n",
    "The same data wrangling and feature engineering steps from Part I are applied to this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31691f28",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e5e5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (27945, 79)\n",
      "\n",
      "Column names:\n",
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
      "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
      "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
      "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
      "       'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
      "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
      "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
      "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy',\n",
      "       'number_of_reviews_ly', 'estimated_occupancy_l365d',\n",
      "       'estimated_revenue_l365d', 'first_review', 'last_review',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27945 entries, 0 to 27944\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            27945 non-null  int64  \n",
      " 1   listing_url                                   27945 non-null  object \n",
      " 2   scrape_id                                     27945 non-null  int64  \n",
      " 3   last_scraped                                  27945 non-null  object \n",
      " 4   source                                        27945 non-null  object \n",
      " 5   name                                          27945 non-null  object \n",
      " 6   description                                   27458 non-null  object \n",
      " 7   neighborhood_overview                         14819 non-null  object \n",
      " 8   picture_url                                   27945 non-null  object \n",
      " 9   host_id                                       27945 non-null  int64  \n",
      " 10  host_url                                      27945 non-null  object \n",
      " 11  host_name                                     27938 non-null  object \n",
      " 12  host_since                                    27937 non-null  object \n",
      " 13  host_location                                 19831 non-null  object \n",
      " 14  host_about                                    19782 non-null  object \n",
      " 15  host_response_time                            27244 non-null  object \n",
      " 16  host_response_rate                            27244 non-null  object \n",
      " 17  host_acceptance_rate                          27525 non-null  object \n",
      " 18  host_is_superhost                             25929 non-null  object \n",
      " 19  host_thumbnail_url                            27937 non-null  object \n",
      " 20  host_picture_url                              27937 non-null  object \n",
      " 21  host_neighbourhood                            7319 non-null   object \n",
      " 22  host_listings_count                           27937 non-null  float64\n",
      " 23  host_total_listings_count                     27937 non-null  float64\n",
      " 24  host_verifications                            27937 non-null  object \n",
      " 25  host_has_profile_pic                          27937 non-null  object \n",
      " 26  host_identity_verified                        27937 non-null  object \n",
      " 27  neighbourhood                                 14819 non-null  object \n",
      " 28  neighbourhood_cleansed                        27945 non-null  object \n",
      " 29  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 30  latitude                                      27945 non-null  float64\n",
      " 31  longitude                                     27945 non-null  float64\n",
      " 32  property_type                                 27945 non-null  object \n",
      " 33  room_type                                     27945 non-null  object \n",
      " 34  accommodates                                  27945 non-null  int64  \n",
      " 35  bathrooms                                     25482 non-null  float64\n",
      " 36  bathrooms_text                                27897 non-null  object \n",
      " 37  bedrooms                                      27637 non-null  float64\n",
      " 38  beds                                          25486 non-null  float64\n",
      " 39  amenities                                     27945 non-null  object \n",
      " 40  price                                         25480 non-null  object \n",
      " 41  minimum_nights                                27945 non-null  int64  \n",
      " 42  maximum_nights                                27945 non-null  int64  \n",
      " 43  minimum_minimum_nights                        27930 non-null  float64\n",
      " 44  maximum_minimum_nights                        27930 non-null  float64\n",
      " 45  minimum_maximum_nights                        27930 non-null  float64\n",
      " 46  maximum_maximum_nights                        27930 non-null  float64\n",
      " 47  minimum_nights_avg_ntm                        27945 non-null  float64\n",
      " 48  maximum_nights_avg_ntm                        27945 non-null  float64\n",
      " 49  calendar_updated                              0 non-null      float64\n",
      " 50  has_availability                              27826 non-null  object \n",
      " 51  availability_30                               27945 non-null  int64  \n",
      " 52  availability_60                               27945 non-null  int64  \n",
      " 53  availability_90                               27945 non-null  int64  \n",
      " 54  availability_365                              27945 non-null  int64  \n",
      " 55  calendar_last_scraped                         27945 non-null  object \n",
      " 56  number_of_reviews                             27945 non-null  int64  \n",
      " 57  number_of_reviews_ltm                         27945 non-null  int64  \n",
      " 58  number_of_reviews_l30d                        27945 non-null  int64  \n",
      " 59  availability_eoy                              27945 non-null  int64  \n",
      " 60  number_of_reviews_ly                          27945 non-null  int64  \n",
      " 61  estimated_occupancy_l365d                     27945 non-null  int64  \n",
      " 62  estimated_revenue_l365d                       25480 non-null  float64\n",
      " 63  first_review                                  24009 non-null  object \n",
      " 64  last_review                                   24009 non-null  object \n",
      " 65  review_scores_rating                          24009 non-null  float64\n",
      " 66  review_scores_accuracy                        24008 non-null  float64\n",
      " 67  review_scores_cleanliness                     24008 non-null  float64\n",
      " 68  review_scores_checkin                         24008 non-null  float64\n",
      " 69  review_scores_communication                   24008 non-null  float64\n",
      " 70  review_scores_location                        24008 non-null  float64\n",
      " 71  review_scores_value                           24008 non-null  float64\n",
      " 72  license                                       27929 non-null  object \n",
      " 73  instant_bookable                              27945 non-null  object \n",
      " 74  calculated_host_listings_count                27945 non-null  int64  \n",
      " 75  calculated_host_listings_count_entire_homes   27945 non-null  int64  \n",
      " 76  calculated_host_listings_count_private_rooms  27945 non-null  int64  \n",
      " 77  calculated_host_listings_count_shared_rooms   27945 non-null  int64  \n",
      " 78  reviews_per_month                             24009 non-null  float64\n",
      "dtypes: float64(24), int64(20), object(35)\n",
      "memory usage: 16.8+ MB\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197677</td>\n",
       "      <td>https://www.airbnb.com/rooms/197677</td>\n",
       "      <td>20250929042135</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Oshiage Holiday Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/38437056/d27f...</td>\n",
       "      <td>964081</td>\n",
       "      <td>...</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.80</td>\n",
       "      <td>M130003350</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>776070</td>\n",
       "      <td>https://www.airbnb.com/rooms/776070</td>\n",
       "      <td>20250929042135</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Kero-kero room 1F</td>\n",
       "      <td>We have been in airbnb since 2011 and it has g...</td>\n",
       "      <td>We love Nishinippori because is nearer to Toky...</td>\n",
       "      <td>https://a0.muscache.com/pictures/efd9f039-dbd2...</td>\n",
       "      <td>801494</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.92</td>\n",
       "      <td>M130000243</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905944</td>\n",
       "      <td>https://www.airbnb.com/rooms/905944</td>\n",
       "      <td>20250929042135</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>4F Spacious Apartment in Shinjuku / Shibuya Tokyo</td>\n",
       "      <td>NEWLY RENOVATED property entirely for you &amp; yo...</td>\n",
       "      <td>Hatagaya is a great neighborhood located 4 min...</td>\n",
       "      <td>https://a0.muscache.com/pictures/hosting/Hosti...</td>\n",
       "      <td>4847803</td>\n",
       "      <td>...</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.81</td>\n",
       "      <td>Hotels and Inns Business Act | 渋谷区保健所長 | 31渋健生...</td>\n",
       "      <td>t</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016831</td>\n",
       "      <td>https://www.airbnb.com/rooms/1016831</td>\n",
       "      <td>20250929042135</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>5 mins Shibuya Cat modern sunny  Shimokita</td>\n",
       "      <td>Hi there, I am Wakana and I live with my two f...</td>\n",
       "      <td>The location is walkable distance to famous Sh...</td>\n",
       "      <td>https://a0.muscache.com/pictures/airflow/Hosti...</td>\n",
       "      <td>5596383</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.89</td>\n",
       "      <td>M130001107</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196177</td>\n",
       "      <td>https://www.airbnb.com/rooms/1196177</td>\n",
       "      <td>20250929042135</td>\n",
       "      <td>2025-09-29</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Homestay at Host's House -  Senju-Ohashi Station</td>\n",
       "      <td>Our accommodation offers:  &lt;br /&gt;&lt;br /&gt;1. **Gr...</td>\n",
       "      <td>There are shopping mall near Senjuohashi stati...</td>\n",
       "      <td>https://a0.muscache.com/pictures/72890882/05ec...</td>\n",
       "      <td>5686404</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.83</td>\n",
       "      <td>M130007760</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           listing_url       scrape_id last_scraped  \\\n",
       "0   197677   https://www.airbnb.com/rooms/197677  20250929042135   2025-09-30   \n",
       "1   776070   https://www.airbnb.com/rooms/776070  20250929042135   2025-09-29   \n",
       "2   905944   https://www.airbnb.com/rooms/905944  20250929042135   2025-09-29   \n",
       "3  1016831  https://www.airbnb.com/rooms/1016831  20250929042135   2025-09-29   \n",
       "4  1196177  https://www.airbnb.com/rooms/1196177  20250929042135   2025-09-29   \n",
       "\n",
       "        source                                               name  \\\n",
       "0  city scrape                          Oshiage Holiday Apartment   \n",
       "1  city scrape                                  Kero-kero room 1F   \n",
       "2  city scrape  4F Spacious Apartment in Shinjuku / Shibuya Tokyo   \n",
       "3  city scrape         5 mins Shibuya Cat modern sunny  Shimokita   \n",
       "4  city scrape   Homestay at Host's House -  Senju-Ohashi Station   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1  We have been in airbnb since 2011 and it has g...   \n",
       "2  NEWLY RENOVATED property entirely for you & yo...   \n",
       "3  Hi there, I am Wakana and I live with my two f...   \n",
       "4  Our accommodation offers:  <br /><br />1. **Gr...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0                                                NaN   \n",
       "1  We love Nishinippori because is nearer to Toky...   \n",
       "2  Hatagaya is a great neighborhood located 4 min...   \n",
       "3  The location is walkable distance to famous Sh...   \n",
       "4  There are shopping mall near Senjuohashi stati...   \n",
       "\n",
       "                                         picture_url  host_id  ...  \\\n",
       "0  https://a0.muscache.com/pictures/38437056/d27f...   964081  ...   \n",
       "1  https://a0.muscache.com/pictures/efd9f039-dbd2...   801494  ...   \n",
       "2  https://a0.muscache.com/pictures/hosting/Hosti...  4847803  ...   \n",
       "3  https://a0.muscache.com/pictures/airflow/Hosti...  5596383  ...   \n",
       "4  https://a0.muscache.com/pictures/72890882/05ec...  5686404  ...   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.84                   4.58                4.80   \n",
       "1                        4.98                   4.85                4.92   \n",
       "2                        4.93                   4.81                4.81   \n",
       "3                        4.98                   4.93                4.89   \n",
       "4                        4.91                   4.75                4.83   \n",
       "\n",
       "                                             license instant_bookable  \\\n",
       "0                                         M130003350                f   \n",
       "1                                         M130000243                f   \n",
       "2  Hotels and Inns Business Act | 渋谷区保健所長 | 31渋健生...                t   \n",
       "3                                         M130001107                f   \n",
       "4                                         M130007760                f   \n",
       "\n",
       "  calculated_host_listings_count calculated_host_listings_count_entire_homes  \\\n",
       "0                              1                                           1   \n",
       "1                              1                                           0   \n",
       "2                              9                                           9   \n",
       "3                              1                                           0   \n",
       "4                              1                                           0   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            1   \n",
       "2                                            0   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              1.11  \n",
       "1                                           0              1.74  \n",
       "2                                           0              1.85  \n",
       "3                                           0              1.87  \n",
       "4                                           0              1.01  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "url_tokyo_q3_2025 = \"https://raw.githubusercontent.com/zarizachow/Data-Analysis-3/refs/heads/main/Assignment-1/Data/Raw/Tokyo_listings/Tokyo_2025_29_Sep/listings.csv\"\n",
    "df_tokyo_q3_2025 = pd.read_csv(url_tokyo_q3_2025)\n",
    "\n",
    "# Basic inspection\n",
    "print(\"Shape (rows, columns):\", df_tokyo_q3_2025.shape)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_tokyo_q3_2025.columns)\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "df_tokyo_q3_2025.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df_tokyo_q3_2025.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b223f",
   "metadata": {},
   "source": [
    "**Handle Missing Values**\n",
    "\n",
    "- Identify missing values across numeric and categorical variables to avoid model errors  \n",
    "- Impute numeric variables using median values  \n",
    "- Treat missing categorical values as `\"missing\"` to avoid dropping observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f93b03e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group_cleansed    27945\n",
       "calendar_updated                27945\n",
       "id                                  0\n",
       "number_of_reviews_ltm               0\n",
       "number_of_reviews                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing values\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df_tokyo_q3_2025.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_tokyo_q3_2025.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Impute numeric variables with median\n",
    "for col in numeric_cols:\n",
    "    df_tokyo_q3_2025[col] = df_tokyo_q3_2025[col].fillna(df_tokyo_q3_2025[col].median())\n",
    "\n",
    "# Impute categorical variables with explicit category\n",
    "for col in categorical_cols:\n",
    "    df_tokyo_q3_2025[col] = df_tokyo_q3_2025[col].fillna(\"missing\")\n",
    "\n",
    "# Sanity check\n",
    "df_tokyo_q3_2025.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921dcc0",
   "metadata": {},
   "source": [
    "**Clean and Standardize Numeric Variables**\n",
    "\n",
    "- Clean the `price` column to ensure it is numeric  \n",
    "- Winsorize numeric variables (1st–99th percentile) to reduce the impact of extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3ec16963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>27945.0</td>\n",
       "      <td>9.498094e+17</td>\n",
       "      <td>5.379486e+17</td>\n",
       "      <td>1.051639e+07</td>\n",
       "      <td>7.624382e+17</td>\n",
       "      <td>1.169462e+18</td>\n",
       "      <td>1.362098e+18</td>\n",
       "      <td>1.508563e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrape_id</th>\n",
       "      <td>27945.0</td>\n",
       "      <td>2.025093e+13</td>\n",
       "      <td>9.773612e+00</td>\n",
       "      <td>2.025093e+13</td>\n",
       "      <td>2.025093e+13</td>\n",
       "      <td>2.025093e+13</td>\n",
       "      <td>2.025093e+13</td>\n",
       "      <td>2.025093e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>27945.0</td>\n",
       "      <td>3.789109e+08</td>\n",
       "      <td>2.176778e+08</td>\n",
       "      <td>7.927902e+06</td>\n",
       "      <td>1.895020e+08</td>\n",
       "      <td>4.254235e+08</td>\n",
       "      <td>5.573665e+08</td>\n",
       "      <td>7.114727e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>27945.0</td>\n",
       "      <td>3.010864e+01</td>\n",
       "      <td>4.001565e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.940000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>27945.0</td>\n",
       "      <td>3.865310e+01</td>\n",
       "      <td>5.728311e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>3.420000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count          mean           std           min  \\\n",
       "id                         27945.0  9.498094e+17  5.379486e+17  1.051639e+07   \n",
       "scrape_id                  27945.0  2.025093e+13  9.773612e+00  2.025093e+13   \n",
       "host_id                    27945.0  3.789109e+08  2.176778e+08  7.927902e+06   \n",
       "host_listings_count        27945.0  3.010864e+01  4.001565e+01  1.000000e+00   \n",
       "host_total_listings_count  27945.0  3.865310e+01  5.728311e+01  1.000000e+00   \n",
       "\n",
       "                                    25%           50%           75%  \\\n",
       "id                         7.624382e+17  1.169462e+18  1.362098e+18   \n",
       "scrape_id                  2.025093e+13  2.025093e+13  2.025093e+13   \n",
       "host_id                    1.895020e+08  4.254235e+08  5.573665e+08   \n",
       "host_listings_count        5.000000e+00  1.400000e+01  4.000000e+01   \n",
       "host_total_listings_count  6.000000e+00  1.700000e+01  4.500000e+01   \n",
       "\n",
       "                                    max  \n",
       "id                         1.508563e+18  \n",
       "scrape_id                  2.025093e+13  \n",
       "host_id                    7.114727e+08  \n",
       "host_listings_count        1.940000e+02  \n",
       "host_total_listings_count  3.420000e+02  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and standardize numeric variables\n",
    "\n",
    "# Fix price variable (it may contain strings or missing)\n",
    "df_tokyo_q3_2025[\"price\"] = df_tokyo_q3_2025[\"price\"].replace(\"missing\", np.nan)\n",
    "\n",
    "df_tokyo_q3_2025[\"price\"] = (\n",
    "    df_tokyo_q3_2025[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df_tokyo_q3_2025[\"price\"] = pd.to_numeric(df_tokyo_q3_2025[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Impute missing price values with median\n",
    "df_tokyo_q3_2025[\"price\"] = df_tokyo_q3_2025[\"price\"].fillna(df_tokyo_q3_2025[\"price\"].median())\n",
    "\n",
    "# Update numeric columns after cleaning price\n",
    "numeric_cols = df_tokyo_q3_2025.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Cap extreme values (simple winsorization)\n",
    "for col in numeric_cols:\n",
    "    lower = df_tokyo_q3_2025[col].quantile(0.01)\n",
    "    upper = df_tokyo_q3_2025[col].quantile(0.99)\n",
    "    df_tokyo_q3_2025[col] = df_tokyo_q3_2025[col].clip(lower, upper)\n",
    "\n",
    "# Sanity check\n",
    "df_tokyo_q3_2025[numeric_cols].describe().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8d090784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), np.int64(0), (27945, 79))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure target variable (price) is numeric\n",
    "\n",
    "df_tokyo_q3_2025[\"price\"] = (\n",
    "    df_tokyo_q3_2025[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df_tokyo_q3_2025[\"price\"] = pd.to_numeric(df_tokyo_q3_2025[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where price is missing\n",
    "df_tokyo_q3_2025 = df_tokyo_q3_2025.dropna(subset=[\"price\"])\n",
    "\n",
    "# Sanity check\n",
    "df_tokyo_q3_2025[\"price\"].dtype, df_tokyo_q3_2025[\"price\"].isna().sum(), df_tokyo_q3_2025.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e95ffb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['neighbourhood_group_cleansed', 'calendar_updated', 'scrape_id']\n",
      "New shape: (27945, 76)\n"
     ]
    }
   ],
   "source": [
    "# Drop unusable variables (except id)\n",
    "\n",
    "all_missing_cols = [\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \"calendar_updated\"\n",
    "]\n",
    "\n",
    "id_cols = [\n",
    "    \"scrape_id\"\n",
    "]\n",
    "\n",
    "cols_to_drop = [col for col in all_missing_cols + id_cols if col in df_tokyo_q3_2025.columns]\n",
    "df_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Dropped columns:\", cols_to_drop)\n",
    "print(\"New shape:\", df_tokyo_q3_2025.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f81d3",
   "metadata": {},
   "source": [
    "**Variable Selection for Modelling**\n",
    "\n",
    "- Exclude id, URLs, dates, and free-text fields that are not useful for prediction  \n",
    "- Keep structured listing, host, location, and amenity variables  \n",
    "- Use the same variables across all datasets for out-of-sample comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3ec24",
   "metadata": {},
   "source": [
    "**Extract Amenities**\n",
    "\n",
    "- Convert the amenities text field into binary indicators  \n",
    "- Use the same amenity list as Part I for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "84bfe40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenity_wifi</th>\n",
       "      <th>amenity_kitchen</th>\n",
       "      <th>amenity_air_conditioning</th>\n",
       "      <th>amenity_heating</th>\n",
       "      <th>amenity_washer</th>\n",
       "      <th>amenity_dryer</th>\n",
       "      <th>amenity_elevator</th>\n",
       "      <th>amenity_tv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amenity_wifi  amenity_kitchen  amenity_air_conditioning  amenity_heating  \\\n",
       "0             1                1                         1                1   \n",
       "1             1                0                         1                1   \n",
       "2             1                1                         0                1   \n",
       "3             1                1                         0                1   \n",
       "4             1                0                         0                1   \n",
       "\n",
       "   amenity_washer  amenity_dryer  amenity_elevator  amenity_tv  \n",
       "0               1              1                 0           1  \n",
       "1               0              1                 0           1  \n",
       "2               0              1                 0           1  \n",
       "3               1              1                 0           1  \n",
       "4               1              1                 0           1  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract amenities\n",
    "\n",
    "# Convert amenities column to string\n",
    "df_tokyo_q3_2025[\"amenities\"] = df_tokyo_q3_2025[\"amenities\"].astype(str)\n",
    "\n",
    "# Same selected amenities list as Part I\n",
    "amenities_list = [\n",
    "    \"Wifi\",\n",
    "    \"Kitchen\",\n",
    "    \"Air conditioning\",\n",
    "    \"Heating\",\n",
    "    \"Washer\",\n",
    "    \"Dryer\",\n",
    "    \"Elevator\",\n",
    "    \"TV\"\n",
    "]\n",
    "\n",
    "# Create binary indicators for each amenity\n",
    "for amenity in amenities_list:\n",
    "    df_tokyo_q3_2025[f\"amenity_{amenity.lower().replace(' ', '_')}\"] = (\n",
    "        df_tokyo_q3_2025[\"amenities\"].str.contains(amenity, case=False, regex=False).astype(int)\n",
    "    )\n",
    "\n",
    "# Drop original amenities text field\n",
    "df_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"amenities\"])\n",
    "\n",
    "# Sanity check\n",
    "df_tokyo_q3_2025.filter(like=\"amenity_\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b200b01",
   "metadata": {},
   "source": [
    "**Save Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "96cd804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved (overwritten if existed):\n",
      "Data/Cleaned/Tokyo_listings/tokyo_listings_q3_2025_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned Tokyo Q3 2025 dataset (overwrite if exists)\n",
    "\n",
    "output_path = \"Data/Cleaned/Tokyo_listings/tokyo_listings_q3_2025_clean.csv\"\n",
    "df_tokyo_q3_2025.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved (overwritten if existed):\")\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3c506",
   "metadata": {},
   "source": [
    "**Encoding of Categorical Variables**\n",
    "\n",
    "Categorical variables are encoded within the model pipelines already, ensuring consistent preprocessing across all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f71e3",
   "metadata": {},
   "source": [
    "##### B. Another City in the Same Region: Hong Kong\n",
    "\n",
    "- **City, Country**: Hong Kong, China  \n",
    "- **Dataset**: `listings.csv` (loaded directly from the GitHub repository)  \n",
    "- **Time period**: Latest available data  \n",
    "- **Purpose**: Test geographic validity by applying the models to another city in the same broader region (Asia)\n",
    "- **Reasons for Choosing Hong Kong**\n",
    "    - *Same region*: Hong Kong and Tokyo are both located in East Asia, allowing for a regional validity check\n",
    "    - *Highly urban and dense*: Both cities are large, high-density urban areas where Airbnb listings are mostly apartments\n",
    "    - *Strong short-term rental demand*: Tourism and business travel play an important role in both markets, making pricing more comparable\n",
    "\n",
    "The same data wrangling and feature engineering steps from Part I are applied to this dataset before using the trained models for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97077bf8",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a2a5e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (6801, 79)\n",
      "\n",
      "Column names:\n",
      "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
      "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
      "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
      "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
      "       'host_neighbourhood', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_verifications',\n",
      "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
      "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
      "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
      "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy',\n",
      "       'number_of_reviews_ly', 'estimated_occupancy_l365d',\n",
      "       'estimated_revenue_l365d', 'first_review', 'last_review',\n",
      "       'review_scores_rating', 'review_scores_accuracy',\n",
      "       'review_scores_cleanliness', 'review_scores_checkin',\n",
      "       'review_scores_communication', 'review_scores_location',\n",
      "       'review_scores_value', 'license', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6801 entries, 0 to 6800\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            6801 non-null   int64  \n",
      " 1   listing_url                                   6801 non-null   object \n",
      " 2   scrape_id                                     6801 non-null   int64  \n",
      " 3   last_scraped                                  6801 non-null   object \n",
      " 4   source                                        6801 non-null   object \n",
      " 5   name                                          6801 non-null   object \n",
      " 6   description                                   6682 non-null   object \n",
      " 7   neighborhood_overview                         1581 non-null   object \n",
      " 8   picture_url                                   6801 non-null   object \n",
      " 9   host_id                                       6801 non-null   int64  \n",
      " 10  host_url                                      6801 non-null   object \n",
      " 11  host_name                                     6799 non-null   object \n",
      " 12  host_since                                    6799 non-null   object \n",
      " 13  host_location                                 4591 non-null   object \n",
      " 14  host_about                                    4305 non-null   object \n",
      " 15  host_response_time                            6287 non-null   object \n",
      " 16  host_response_rate                            6287 non-null   object \n",
      " 17  host_acceptance_rate                          6489 non-null   object \n",
      " 18  host_is_superhost                             6731 non-null   object \n",
      " 19  host_thumbnail_url                            6799 non-null   object \n",
      " 20  host_picture_url                              6799 non-null   object \n",
      " 21  host_neighbourhood                            6561 non-null   object \n",
      " 22  host_listings_count                           6799 non-null   float64\n",
      " 23  host_total_listings_count                     6799 non-null   float64\n",
      " 24  host_verifications                            6799 non-null   object \n",
      " 25  host_has_profile_pic                          6799 non-null   object \n",
      " 26  host_identity_verified                        6799 non-null   object \n",
      " 27  neighbourhood                                 1581 non-null   object \n",
      " 28  neighbourhood_cleansed                        6801 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 30  latitude                                      6801 non-null   float64\n",
      " 31  longitude                                     6801 non-null   float64\n",
      " 32  property_type                                 6801 non-null   object \n",
      " 33  room_type                                     6801 non-null   object \n",
      " 34  accommodates                                  6801 non-null   int64  \n",
      " 35  bathrooms                                     5453 non-null   float64\n",
      " 36  bathrooms_text                                6783 non-null   object \n",
      " 37  bedrooms                                      6361 non-null   float64\n",
      " 38  beds                                          5445 non-null   float64\n",
      " 39  amenities                                     6801 non-null   object \n",
      " 40  price                                         5465 non-null   object \n",
      " 41  minimum_nights                                6801 non-null   int64  \n",
      " 42  maximum_nights                                6801 non-null   int64  \n",
      " 43  minimum_minimum_nights                        6799 non-null   float64\n",
      " 44  maximum_minimum_nights                        6799 non-null   float64\n",
      " 45  minimum_maximum_nights                        6799 non-null   float64\n",
      " 46  maximum_maximum_nights                        6799 non-null   float64\n",
      " 47  minimum_nights_avg_ntm                        6801 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        6801 non-null   float64\n",
      " 49  calendar_updated                              0 non-null      float64\n",
      " 50  has_availability                              6739 non-null   object \n",
      " 51  availability_30                               6801 non-null   int64  \n",
      " 52  availability_60                               6801 non-null   int64  \n",
      " 53  availability_90                               6801 non-null   int64  \n",
      " 54  availability_365                              6801 non-null   int64  \n",
      " 55  calendar_last_scraped                         6801 non-null   object \n",
      " 56  number_of_reviews                             6801 non-null   int64  \n",
      " 57  number_of_reviews_ltm                         6801 non-null   int64  \n",
      " 58  number_of_reviews_l30d                        6801 non-null   int64  \n",
      " 59  availability_eoy                              6801 non-null   int64  \n",
      " 60  number_of_reviews_ly                          6801 non-null   int64  \n",
      " 61  estimated_occupancy_l365d                     6801 non-null   int64  \n",
      " 62  estimated_revenue_l365d                       5465 non-null   float64\n",
      " 63  first_review                                  3585 non-null   object \n",
      " 64  last_review                                   3585 non-null   object \n",
      " 65  review_scores_rating                          3585 non-null   float64\n",
      " 66  review_scores_accuracy                        3585 non-null   float64\n",
      " 67  review_scores_cleanliness                     3585 non-null   float64\n",
      " 68  review_scores_checkin                         3585 non-null   float64\n",
      " 69  review_scores_communication                   3585 non-null   float64\n",
      " 70  review_scores_location                        3585 non-null   float64\n",
      " 71  review_scores_value                           3585 non-null   float64\n",
      " 72  license                                       0 non-null      float64\n",
      " 73  instant_bookable                              6801 non-null   object \n",
      " 74  calculated_host_listings_count                6801 non-null   int64  \n",
      " 75  calculated_host_listings_count_entire_homes   6801 non-null   int64  \n",
      " 76  calculated_host_listings_count_private_rooms  6801 non-null   int64  \n",
      " 77  calculated_host_listings_count_shared_rooms   6801 non-null   int64  \n",
      " 78  reviews_per_month                             3585 non-null   float64\n",
      "dtypes: float64(25), int64(20), object(34)\n",
      "memory usage: 4.1+ MB\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103760</td>\n",
       "      <td>https://www.airbnb.com/rooms/103760</td>\n",
       "      <td>20250923203502</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Central Centre 5 min walk to/from Central MTR</td>\n",
       "      <td>Located right in the heart of Central, this 2 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/815221/056993...</td>\n",
       "      <td>304876</td>\n",
       "      <td>...</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248140</td>\n",
       "      <td>https://www.airbnb.com/rooms/248140</td>\n",
       "      <td>20250923203502</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>Bright Studio - Soho - Central HK</td>\n",
       "      <td>Our bright studio apartment is perfect for vis...</td>\n",
       "      <td>The local neighbourhood is quiet and relaxing....</td>\n",
       "      <td>https://a0.muscache.com/pictures/4e5463bc-38be...</td>\n",
       "      <td>1300549</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>263081</td>\n",
       "      <td>https://www.airbnb.com/rooms/263081</td>\n",
       "      <td>20250923203502</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>3 睡房, 2500 平方呎 有工人 Family Friendly! 在中環半山 有車</td>\n",
       "      <td>Mid Level on the top of central, Next to the m...</td>\n",
       "      <td>We are in the most luxury area of HK, conduit ...</td>\n",
       "      <td>https://a0.muscache.com/pictures/7348025/73278...</td>\n",
       "      <td>1370155</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306515</td>\n",
       "      <td>https://www.airbnb.com/rooms/306515</td>\n",
       "      <td>20250923203502</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>HongKong,Central Bright Double Room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/3335548/00a8d...</td>\n",
       "      <td>1576511</td>\n",
       "      <td>...</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378047</td>\n",
       "      <td>https://www.airbnb.com/rooms/378047</td>\n",
       "      <td>20250923203502</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>previous scrape</td>\n",
       "      <td>LUXURY HONG KONG COUNTRY COW SHED</td>\n",
       "      <td>Your bijoux getaway is a one story cottage in ...</td>\n",
       "      <td>We are in the South Lantau foot hills, 20 min ...</td>\n",
       "      <td>https://a0.muscache.com/pictures/hosting/Hosti...</td>\n",
       "      <td>1805628</td>\n",
       "      <td>...</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          listing_url       scrape_id last_scraped  \\\n",
       "0  103760  https://www.airbnb.com/rooms/103760  20250923203502   2025-09-24   \n",
       "1  248140  https://www.airbnb.com/rooms/248140  20250923203502   2025-09-24   \n",
       "2  263081  https://www.airbnb.com/rooms/263081  20250923203502   2025-09-23   \n",
       "3  306515  https://www.airbnb.com/rooms/306515  20250923203502   2025-09-24   \n",
       "4  378047  https://www.airbnb.com/rooms/378047  20250923203502   2025-09-24   \n",
       "\n",
       "            source                                           name  \\\n",
       "0      city scrape  Central Centre 5 min walk to/from Central MTR   \n",
       "1      city scrape              Bright Studio - Soho - Central HK   \n",
       "2      city scrape   3 睡房, 2500 平方呎 有工人 Family Friendly! 在中環半山 有車   \n",
       "3      city scrape            HongKong,Central Bright Double Room   \n",
       "4  previous scrape              LUXURY HONG KONG COUNTRY COW SHED   \n",
       "\n",
       "                                         description  \\\n",
       "0  Located right in the heart of Central, this 2 ...   \n",
       "1  Our bright studio apartment is perfect for vis...   \n",
       "2  Mid Level on the top of central, Next to the m...   \n",
       "3                                                NaN   \n",
       "4  Your bijoux getaway is a one story cottage in ...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0                                                NaN   \n",
       "1  The local neighbourhood is quiet and relaxing....   \n",
       "2  We are in the most luxury area of HK, conduit ...   \n",
       "3                                                NaN   \n",
       "4  We are in the South Lantau foot hills, 20 min ...   \n",
       "\n",
       "                                         picture_url  host_id  ...  \\\n",
       "0  https://a0.muscache.com/pictures/815221/056993...   304876  ...   \n",
       "1  https://a0.muscache.com/pictures/4e5463bc-38be...  1300549  ...   \n",
       "2  https://a0.muscache.com/pictures/7348025/73278...  1370155  ...   \n",
       "3  https://a0.muscache.com/pictures/3335548/00a8d...  1576511  ...   \n",
       "4  https://a0.muscache.com/pictures/hosting/Hosti...  1805628  ...   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.63                   4.72                4.41   \n",
       "1                        4.98                   4.76                4.80   \n",
       "2                         NaN                    NaN                 NaN   \n",
       "3                        4.84                   4.89                4.79   \n",
       "4                        4.94                   4.52                4.62   \n",
       "\n",
       "  license instant_bookable calculated_host_listings_count  \\\n",
       "0     NaN                f                              1   \n",
       "1     NaN                f                              1   \n",
       "2     NaN                f                              1   \n",
       "3     NaN                f                              1   \n",
       "4     NaN                f                              1   \n",
       "\n",
       "  calculated_host_listings_count_entire_homes  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           0   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              1.82  \n",
       "1                                           0              1.35  \n",
       "2                                           0               NaN  \n",
       "3                                           0              0.11  \n",
       "4                                           0              0.51  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "url_hk_latest = \"https://raw.githubusercontent.com/zarizachow/Data-Analysis-3/refs/heads/main/Assignment-1/Data/Raw/HongKong_listings/listings.csv\"\n",
    "df_hk_latest = pd.read_csv(url_hk_latest)\n",
    "\n",
    "# Basic inspection\n",
    "print(\"Shape (rows, columns):\", df_hk_latest.shape)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_hk_latest.columns)\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "df_hk_latest.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df_hk_latest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24755e43",
   "metadata": {},
   "source": [
    "**Handle Missing Values**\n",
    "\n",
    "- Identify missing values across numeric and categorical variables to avoid model errors  \n",
    "- Impute numeric variables using median values  \n",
    "- Treat missing categorical values as `\"missing\"` to avoid dropping observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ab0cc2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calendar_updated                6801\n",
       "license                         6801\n",
       "neighbourhood_group_cleansed    6801\n",
       "has_availability                   0\n",
       "number_of_reviews                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing values\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df_hk_latest.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_hk_latest.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Impute numeric variables with median\n",
    "for col in numeric_cols:\n",
    "    df_hk_latest[col] = df_hk_latest[col].fillna(df_hk_latest[col].median())\n",
    "\n",
    "# Impute categorical variables with explicit category\n",
    "for col in categorical_cols:\n",
    "    df_hk_latest[col] = df_hk_latest[col].fillna(\"missing\")\n",
    "\n",
    "# Sanity check\n",
    "df_hk_latest.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8562e",
   "metadata": {},
   "source": [
    "**Clean and Standardize Numeric Variables**\n",
    "\n",
    "- Clean the `price` column to ensure it is numeric  \n",
    "- Winsorize numeric variables (1st–99th percentile) to reduce the impact of extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "096763fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>6801.0</td>\n",
       "      <td>6.270046e+17</td>\n",
       "      <td>5.680543e+17</td>\n",
       "      <td>1.910193e+06</td>\n",
       "      <td>3.299679e+07</td>\n",
       "      <td>8.266702e+17</td>\n",
       "      <td>1.131615e+18</td>\n",
       "      <td>1.492672e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrape_id</th>\n",
       "      <td>6801.0</td>\n",
       "      <td>2.025092e+13</td>\n",
       "      <td>1.738409e+00</td>\n",
       "      <td>2.025092e+13</td>\n",
       "      <td>2.025092e+13</td>\n",
       "      <td>2.025092e+13</td>\n",
       "      <td>2.025092e+13</td>\n",
       "      <td>2.025092e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>6801.0</td>\n",
       "      <td>1.867935e+08</td>\n",
       "      <td>2.081109e+08</td>\n",
       "      <td>1.654196e+06</td>\n",
       "      <td>1.723227e+07</td>\n",
       "      <td>9.724013e+07</td>\n",
       "      <td>3.533266e+08</td>\n",
       "      <td>6.892197e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>6801.0</td>\n",
       "      <td>1.122978e+02</td>\n",
       "      <td>1.434581e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>6801.0</td>\n",
       "      <td>1.452341e+02</td>\n",
       "      <td>1.975859e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>8.850000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std           min  \\\n",
       "id                         6801.0  6.270046e+17  5.680543e+17  1.910193e+06   \n",
       "scrape_id                  6801.0  2.025092e+13  1.738409e+00  2.025092e+13   \n",
       "host_id                    6801.0  1.867935e+08  2.081109e+08  1.654196e+06   \n",
       "host_listings_count        6801.0  1.122978e+02  1.434581e+02  1.000000e+00   \n",
       "host_total_listings_count  6801.0  1.452341e+02  1.975859e+02  1.000000e+00   \n",
       "\n",
       "                                    25%           50%           75%  \\\n",
       "id                         3.299679e+07  8.266702e+17  1.131615e+18   \n",
       "scrape_id                  2.025092e+13  2.025092e+13  2.025092e+13   \n",
       "host_id                    1.723227e+07  9.724013e+07  3.533266e+08   \n",
       "host_listings_count        4.000000e+00  3.000000e+01  2.170000e+02   \n",
       "host_total_listings_count  7.000000e+00  3.800000e+01  3.090000e+02   \n",
       "\n",
       "                                    max  \n",
       "id                         1.492672e+18  \n",
       "scrape_id                  2.025092e+13  \n",
       "host_id                    6.892197e+08  \n",
       "host_listings_count        5.170000e+02  \n",
       "host_total_listings_count  8.850000e+02  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and standardize numeric variables\n",
    "\n",
    "# Fix price variable (it may contain strings or missing)\n",
    "df_hk_latest[\"price\"] = df_hk_latest[\"price\"].replace(\"missing\", np.nan)\n",
    "\n",
    "df_hk_latest[\"price\"] = (\n",
    "    df_hk_latest[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df_hk_latest[\"price\"] = pd.to_numeric(df_hk_latest[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Impute missing price values with median\n",
    "df_hk_latest[\"price\"] = df_hk_latest[\"price\"].fillna(df_hk_latest[\"price\"].median())\n",
    "\n",
    "# Update numeric columns after cleaning price\n",
    "numeric_cols = df_hk_latest.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Cap extreme values (simple winsorization)\n",
    "for col in numeric_cols:\n",
    "    lower = df_hk_latest[col].quantile(0.01)\n",
    "    upper = df_hk_latest[col].quantile(0.99)\n",
    "    df_hk_latest[col] = df_hk_latest[col].clip(lower, upper)\n",
    "\n",
    "# Sanity check\n",
    "df_hk_latest[numeric_cols].describe().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3a0081c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), np.int64(0), (6801, 79))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure target variable (price) is numeric\n",
    "\n",
    "df_hk_latest[\"price\"] = (\n",
    "    df_hk_latest[\"price\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df_hk_latest[\"price\"] = pd.to_numeric(df_hk_latest[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where price is missing\n",
    "df_hk_latest = df_hk_latest.dropna(subset=[\"price\"])\n",
    "\n",
    "# Sanity check\n",
    "df_hk_latest[\"price\"].dtype, df_hk_latest[\"price\"].isna().sum(), df_hk_latest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "990cdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['neighbourhood_group_cleansed', 'calendar_updated', 'scrape_id']\n",
      "New shape: (6801, 76)\n"
     ]
    }
   ],
   "source": [
    "# Drop unusable variables (except id)\n",
    "\n",
    "all_missing_cols = [\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \"calendar_updated\"\n",
    "]\n",
    "\n",
    "id_cols = [\n",
    "    \"scrape_id\"\n",
    "]\n",
    "\n",
    "cols_to_drop = [col for col in all_missing_cols + id_cols if col in df_hk_latest.columns]\n",
    "df_hk_latest = df_hk_latest.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Dropped columns:\", cols_to_drop)\n",
    "print(\"New shape:\", df_hk_latest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af241c77",
   "metadata": {},
   "source": [
    "**Variable Selection for Modelling**\n",
    "\n",
    "Before extracting amenities, I remove variables that are not useful for prediction.\n",
    "\n",
    "- Drop identifiers, URLs, and date fields  \n",
    "- Drop free-text fields (titles, descriptions, long notes)  \n",
    "- Keep structured listing, host, and location variables for modelling consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef10bf2",
   "metadata": {},
   "source": [
    "**Extract Amenities**\n",
    "\n",
    "- Convert the amenities text field into binary indicators  \n",
    "- Use the same amenity list as Part I for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3595c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amenity_wifi</th>\n",
       "      <th>amenity_kitchen</th>\n",
       "      <th>amenity_air_conditioning</th>\n",
       "      <th>amenity_heating</th>\n",
       "      <th>amenity_washer</th>\n",
       "      <th>amenity_dryer</th>\n",
       "      <th>amenity_elevator</th>\n",
       "      <th>amenity_tv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amenity_wifi  amenity_kitchen  amenity_air_conditioning  amenity_heating  \\\n",
       "0             1                1                         0                1   \n",
       "1             1                1                         0                1   \n",
       "2             1                1                         1                1   \n",
       "3             1                1                         1                0   \n",
       "4             1                1                         1                1   \n",
       "\n",
       "   amenity_washer  amenity_dryer  amenity_elevator  amenity_tv  \n",
       "0               1              1                 0           1  \n",
       "1               0              1                 1           1  \n",
       "2               1              1                 1           1  \n",
       "3               1              1                 1           1  \n",
       "4               1              1                 0           0  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract amenities\n",
    "\n",
    "# Convert amenities column to string\n",
    "df_hk_latest[\"amenities\"] = df_hk_latest[\"amenities\"].astype(str)\n",
    "\n",
    "# Same selected amenities list as Part I\n",
    "amenities_list = [\n",
    "    \"Wifi\",\n",
    "    \"Kitchen\",\n",
    "    \"Air conditioning\",\n",
    "    \"Heating\",\n",
    "    \"Washer\",\n",
    "    \"Dryer\",\n",
    "    \"Elevator\",\n",
    "    \"TV\"\n",
    "]\n",
    "\n",
    "# Create binary indicators for each amenity\n",
    "for amenity in amenities_list:\n",
    "    df_hk_latest[f\"amenity_{amenity.lower().replace(' ', '_')}\"] = (\n",
    "        df_hk_latest[\"amenities\"].str.contains(amenity, case=False, regex=False).astype(int)\n",
    "    )\n",
    "\n",
    "# Drop original amenities text field\n",
    "df_hk_latest = df_hk_latest.drop(columns=[\"amenities\"])\n",
    "\n",
    "# Sanity check\n",
    "df_hk_latest.filter(like=\"amenity_\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d11fe7",
   "metadata": {},
   "source": [
    "**Save Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c6f32077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved (overwritten if existed):\n",
      "Data/Cleaned/HongKong_listings/hongkong_listings_latest_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned Hong Kong dataset (overwrite if exists)\n",
    "\n",
    "output_path = \"Data/Cleaned/HongKong_listings/hongkong_listings_latest_clean.csv\"\n",
    "df_hk_latest.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved (overwritten if existed):\")\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2420af",
   "metadata": {},
   "source": [
    "**Encoding of Categorical Variables**\n",
    "\n",
    "Categorical variables are encoded within the model pipelines already, ensuring consistent preprocessing across all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55627870",
   "metadata": {},
   "source": [
    "### Step 6: Use the 5 Core Models on the 'Live' Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77895ace",
   "metadata": {},
   "source": [
    "##### A. Later Date: Tokyo (Q3 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9ff68",
   "metadata": {},
   "source": [
    "**OLS Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "de8f489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Q3 2025 - OLS RMSE: 11416.208545812342\n",
      "Tokyo Q3 2025 - OLS Runtime (s): 6.97\n"
     ]
    }
   ],
   "source": [
    "# OLS model on Tokyo Q3 2025 dataset\n",
    "\n",
    "# Define target and features\n",
    "y_tokyo_q3_2025 = df_tokyo_q3_2025[\"price\"]\n",
    "X_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split (same random state for consistency)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tokyo_q3_2025, y_tokyo_q3_2025, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OLS pipeline\n",
    "ols_tokyo_q3_2025 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "ols_tokyo_q3_2025.fit(X_train, y_train)\n",
    "y_pred = ols_tokyo_q3_2025.predict(X_test)\n",
    "\n",
    "runtime_ols_tokyo_q3_2025 = time.time() - start_time\n",
    "\n",
    "# RMSE\n",
    "rmse_ols_tokyo_q3_2025 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Tokyo Q3 2025 - OLS RMSE:\", rmse_ols_tokyo_q3_2025)\n",
    "print(\"Tokyo Q3 2025 - OLS Runtime (s):\", round(runtime_ols_tokyo_q3_2025, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1b539",
   "metadata": {},
   "source": [
    "**LASSO Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c9f0f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Q3 2025 - LASSO RMSE: 12501.681388469251\n",
      "Tokyo Q3 2025 - LASSO Runtime (s): 14.15\n"
     ]
    }
   ],
   "source": [
    " # LASSO on Tokyo Q3 2025 dataset\n",
    "\n",
    "# Restrict categorical variables (same as Part I)\n",
    "categorical_keep = [\n",
    "    \"room_type\",\n",
    "    \"property_type\",\n",
    "    \"neighbourhood_cleansed\",\n",
    "    \"host_is_superhost\",\n",
    "    \"instant_bookable\"\n",
    "]\n",
    "\n",
    "categorical_keep = [c for c in categorical_keep if c in df_tokyo_q3_2025.columns]\n",
    "\n",
    "# Define target and features\n",
    "y_tokyo_q3_2025 = df_tokyo_q3_2025[\"price\"]\n",
    "X_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Drop other object/string columns\n",
    "object_cols = X_tokyo_q3_2025.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in object_cols if c not in categorical_keep]\n",
    "X_tokyo_q3_2025 = X_tokyo_q3_2025.drop(columns=drop_cols)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tokyo_q3_2025, y_tokyo_q3_2025, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_lasso = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LASSO pipeline\n",
    "lasso_tokyo_q3_2025 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_lasso),\n",
    "        (\"model\", Lasso(alpha=1.0, max_iter=3000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "lasso_tokyo_q3_2025.fit(X_train, y_train)\n",
    "y_pred = lasso_tokyo_q3_2025.predict(X_test)\n",
    "\n",
    "runtime_lasso_tokyo_q3_2025 = time.time() - start_time\n",
    "\n",
    "# RMSE\n",
    "rmse_lasso_tokyo_q3_2025 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Tokyo Q3 2025 - LASSO RMSE:\", rmse_lasso_tokyo_q3_2025)\n",
    "print(\"Tokyo Q3 2025 - LASSO Runtime (s):\", round(runtime_lasso_tokyo_q3_2025, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59322f",
   "metadata": {},
   "source": [
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ea6df125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Q3 2025 - Random Forest RMSE: 16035.611614317326\n",
      "Tokyo Q3 2025 - Random Forest Runtime (s): 1.31\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model on Tokyo Q3 2025 dataset\n",
    "\n",
    "# Define target and features\n",
    "y_tokyo_q3_2025 = df_tokyo_q3_2025[\"price\"]\n",
    "X_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split (same random state for consistency)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tokyo_q3_2025, y_tokyo_q3_2025, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing (same as Part I)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest pipeline (same settings as Part I)\n",
    "rf_tokyo_q3_2025 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_rf),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "rf_tokyo_q3_2025.fit(X_train, y_train)\n",
    "y_pred = rf_tokyo_q3_2025.predict(X_test)\n",
    "\n",
    "runtime_rf_tokyo_q3_2025 = time.time() - start_time\n",
    "\n",
    "# RMSE\n",
    "rmse_rf_tokyo_q3_2025 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Tokyo Q3 2025 - Random Forest RMSE:\", rmse_rf_tokyo_q3_2025)\n",
    "print(\"Tokyo Q3 2025 - Random Forest Runtime (s):\", round(runtime_rf_tokyo_q3_2025, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc9f55",
   "metadata": {},
   "source": [
    "**Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0d004372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Q3 2025 - Gradient Boosting RMSE: 10117.57589237642\n",
      "Tokyo Q3 2025 - Gradient Boosting Runtime (s): 27.15\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting on Tokyo Q3 2025\n",
    "\n",
    "# Define target and features\n",
    "y_tokyo_q3_2025 = df_tokyo_q3_2025[\"price\"]\n",
    "X_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tokyo_q3_2025, y_tokyo_q3_2025, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Gradient Boosting pipeline\n",
    "gb_tokyo_q3_2025 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_gb),\n",
    "        (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "gb_tokyo_q3_2025.fit(X_train, y_train)\n",
    "y_pred = gb_tokyo_q3_2025.predict(X_test)\n",
    "\n",
    "runtime_gb_tokyo_q3_2025 = time.time() - start_time\n",
    "\n",
    "# RMSE\n",
    "rmse_gb_tokyo_q3_2025 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Tokyo Q3 2025 - Gradient Boosting RMSE:\", rmse_gb_tokyo_q3_2025)\n",
    "print(\"Tokyo Q3 2025 - Gradient Boosting Runtime (s):\", round(runtime_gb_tokyo_q3_2025, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921bece",
   "metadata": {},
   "source": [
    "**Decision Tree (CART)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ab603ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo Q3 2025 - Decision Tree RMSE: 10271.0395070093\n",
      "Tokyo Q3 2025 - Decision Tree Runtime (s): 28.28\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (CART) on Tokyo Q3 2025\n",
    "\n",
    "# Define target and features\n",
    "y_tokyo_q3_2025 = df_tokyo_q3_2025[\"price\"]\n",
    "X_tokyo_q3_2025 = df_tokyo_q3_2025.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tokyo_q3_2025, y_tokyo_q3_2025, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing (same as RF/GB)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_dt = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Decision Tree pipeline\n",
    "dt_tokyo_q3_2025 = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_dt),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "dt_tokyo_q3_2025.fit(X_train, y_train)\n",
    "y_pred = dt_tokyo_q3_2025.predict(X_test)\n",
    "\n",
    "runtime_dt_tokyo_q3_2025 = time.time() - start_time\n",
    "\n",
    "# RMSE\n",
    "rmse_dt_tokyo_q3_2025 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Tokyo Q3 2025 - Decision Tree RMSE:\", rmse_dt_tokyo_q3_2025)\n",
    "print(\"Tokyo Q3 2025 - Decision Tree Runtime (s):\", round(runtime_dt_tokyo_q3_2025, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c84bab",
   "metadata": {},
   "source": [
    "##### Horserace Table (Tokyo Q3 2025)\n",
    "\n",
    "The horserace table compares the 5 models in terms of predictive accuracy and computation time.\n",
    "\n",
    "- **RMSE** is used to measure out-of-sample prediction error. Lower RMSE values indicate better predictive performance.\n",
    "- **Time** captures total model training and prediction time\n",
    "- All models use the same data and train–test split\n",
    "- This ensures results are directly comparable across models\n",
    "\n",
    "| Model                    | RMSE (Test Set) | Runtime (seconds) |\n",
    "|--------------------------|----------------:|------------------:|\n",
    "| OLS                      | 11,416.21       | 6.97              |\n",
    "| LASSO                    | 12,501.68       | 14.15             |\n",
    "| Random Forest            | 16,035.61       | 1.31              |\n",
    "| Gradient Boosting        | 10,117.58       | 27.15             |\n",
    "| Decision Tree (CART)     | 10,271.04       | 28.28             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd917bc7",
   "metadata": {},
   "source": [
    "##### Discussion of Performance (Tokyo Q3 2025)\n",
    "\n",
    "The horserace table shows clear differences across the models in terms of fit and runtime.\n",
    "\n",
    "- **OLS**  \n",
    "  OLS performs well as a baseline model, with a relatively low RMSE and moderate runtime.\n",
    "\n",
    "- **LASSO**  \n",
    "  LASSO performs worse than OLS, suggesting that shrinkage/regularisation does not improve prediction here.\n",
    "\n",
    "- **Random Forest**  \n",
    "  Random Forest is fast in this run, but it has the highest RMSE, meaning it performs the worst on Tokyo Q3 2025.\n",
    "\n",
    "- **Gradient Boosting**  \n",
    "  Gradient Boosting has the lowest RMSE, so it predicts best here, but it is the slowest to run.\n",
    "\n",
    "- **Decision Tree (CART)**  \n",
    "  CART performs almost as well as Gradient Boosting in RMSE, but it is also very slow in this run and can be less stable because it is a single tree.\n",
    "\n",
    "Overall, the results show a trade-off between accuracy and computation time.  \n",
    "In this dataset, **Gradient Boosting gives the best accuracy**, while **OLS remains a strong and simpler baseline**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b32d6e",
   "metadata": {},
   "source": [
    "##### B. Another City in the Same Region: Hong Kong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc48576",
   "metadata": {},
   "source": [
    "**OLS Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong - OLS RMSE: 455.9624123770325\n",
      "Hong Kong - OLS Runtime (s): 1.38\n"
     ]
    }
   ],
   "source": [
    "# OLS Model on Hong Kong\n",
    "\n",
    "# Define target and features\n",
    "y_hk = df_hk_latest[\"price\"]\n",
    "X_hk = df_hk_latest.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_hk, y_hk, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OLS pipeline\n",
    "ols_hk = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "ols_hk.fit(X_train, y_train)\n",
    "y_pred = ols_hk.predict(X_test)\n",
    "\n",
    "runtime_ols_hk = time.time() - start_time\n",
    "rmse_ols_hk = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Hong Kong - OLS RMSE:\", rmse_ols_hk)\n",
    "print(\"Hong Kong - OLS Runtime (s):\", round(runtime_ols_hk, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c208e60e",
   "metadata": {},
   "source": [
    "**LASSO Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44413bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong - LASSO RMSE: 546.482964740583\n",
      "Hong Kong - LASSO Runtime (s): 0.61\n"
     ]
    }
   ],
   "source": [
    "# LASSO Model on Hong Kong\n",
    "\n",
    "# Restrict categorical variables (same as Part I)\n",
    "categorical_keep = [\n",
    "    \"room_type\",\n",
    "    \"property_type\",\n",
    "    \"neighbourhood_cleansed\",\n",
    "    \"host_is_superhost\",\n",
    "    \"instant_bookable\"\n",
    "]\n",
    "categorical_keep = [c for c in categorical_keep if c in df_hk_latest.columns]\n",
    "\n",
    "# Define target and features\n",
    "y_hk = df_hk_latest[\"price\"]\n",
    "X_hk = df_hk_latest.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Drop other object/string columns (keep only selected categoricals)\n",
    "object_cols = X_hk.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "drop_cols = [c for c in object_cols if c not in categorical_keep]\n",
    "X_hk = X_hk.drop(columns=drop_cols)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_hk, y_hk, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_lasso = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# LASSO pipeline\n",
    "lasso_hk = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_lasso),\n",
    "        (\"model\", Lasso(alpha=1.0, max_iter=3000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "lasso_hk.fit(X_train, y_train)\n",
    "y_pred = lasso_hk.predict(X_test)\n",
    "\n",
    "runtime_lasso_hk = time.time() - start_time\n",
    "rmse_lasso_hk = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Hong Kong - LASSO RMSE:\", rmse_lasso_hk)\n",
    "print(\"Hong Kong - LASSO Runtime (s):\", round(runtime_lasso_hk, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e879f42",
   "metadata": {},
   "source": [
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "914e9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong - Random Forest RMSE: 636.6375035558883\n",
      "Hong Kong - Random Forest Runtime (s): 0.43\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model on Hong Kong\n",
    "\n",
    "# Define target and features\n",
    "y_hk = df_hk_latest[\"price\"]\n",
    "X_hk = df_hk_latest.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_hk, y_hk, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest pipeline (same as Part I)\n",
    "rf_hk = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_rf),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            min_samples_leaf=5,\n",
    "            max_features=\"sqrt\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "rf_hk.fit(X_train, y_train)\n",
    "y_pred = rf_hk.predict(X_test)\n",
    "\n",
    "runtime_rf_hk = time.time() - start_time\n",
    "rmse_rf_hk = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Hong Kong - Random Forest RMSE:\", rmse_rf_hk)\n",
    "print(\"Hong Kong - Random Forest Runtime (s):\", round(runtime_rf_hk, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b58b6",
   "metadata": {},
   "source": [
    "**Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "03b5dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong - Gradient Boosting RMSE: 466.0048116110818\n",
      "Hong Kong - Gradient Boosting Runtime (s): 5.14\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model on Hong Kong\n",
    "\n",
    "# Define target and features\n",
    "y_hk = df_hk_latest[\"price\"]\n",
    "X_hk = df_hk_latest.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_hk, y_hk, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Gradient Boosting pipeline\n",
    "gb_hk = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_gb),\n",
    "        (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "gb_hk.fit(X_train, y_train)\n",
    "y_pred = gb_hk.predict(X_test)\n",
    "\n",
    "runtime_gb_hk = time.time() - start_time\n",
    "rmse_gb_hk = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Hong Kong - Gradient Boosting RMSE:\", rmse_gb_hk)\n",
    "print(\"Hong Kong - Gradient Boosting Runtime (s):\", round(runtime_gb_hk, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4cfd3",
   "metadata": {},
   "source": [
    "**Decision Tree (CART)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c0f6f4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hong Kong - Decision Tree RMSE: 499.90527905145404\n",
      "Hong Kong - Decision Tree Runtime (s): 1.92\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (CART) on Hong Kong\n",
    "\n",
    "# Define target and features\n",
    "y_hk = df_hk_latest[\"price\"]\n",
    "X_hk = df_hk_latest.drop(columns=[\"price\", \"id\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_hk, y_hk, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Preprocessing (same as RF/GB)\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_dt = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Decision Tree pipeline\n",
    "dt_hk = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_dt),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit + predict with timing\n",
    "start_time = time.time()\n",
    "\n",
    "dt_hk.fit(X_train, y_train)\n",
    "y_pred = dt_hk.predict(X_test)\n",
    "\n",
    "runtime_dt_hk = time.time() - start_time\n",
    "rmse_dt_hk = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Hong Kong - Decision Tree RMSE:\", rmse_dt_hk)\n",
    "print(\"Hong Kong - Decision Tree Runtime (s):\", round(runtime_dt_hk, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b2217",
   "metadata": {},
   "source": [
    "##### Horserace Table\n",
    "\n",
    "The horserace table compares the 5 models in terms of predictive accuracy and computation time.\n",
    "\n",
    "- **RMSE** is used to measure out-of-sample prediction error. Lower RMSE values indicate better predictive performance.\n",
    "- **Time** captures total model training and prediction time\n",
    "- All models use the same data and train–test split\n",
    "- This ensures results are directly comparable across models\n",
    "\n",
    "| Model                    | RMSE (Test Set) | Runtime (seconds) |\n",
    "|--------------------------|----------------:|------------------:|\n",
    "| OLS                      | 455.96          | 1.38              |\n",
    "| LASSO                    | 546.48          | 0.61              |\n",
    "| Random Forest            | 636.64          | 0.43              |\n",
    "| Gradient Boosting        | 466.00          | 5.14              |\n",
    "| Decision Tree (CART)     | 499.91          | 1.92              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb56e28",
   "metadata": {},
   "source": [
    "##### Discussion of Performance\n",
    "\n",
    "The horserace table shows clear differences across the models in terms of fit and runtime.\n",
    "\n",
    "- **OLS**  \n",
    "  OLS performs best here (lowest RMSE), while staying fast. It is a strong baseline on the Hong Kong dataset.\n",
    "\n",
    "- **LASSO**  \n",
    "  LASSO performs worse than OLS, suggesting that shrinkage/regularisation is not improving prediction in this setup.\n",
    "\n",
    "- **Random Forest**  \n",
    "  Random Forest performs the worst in terms of RMSE, even though it runs quickly in this version. This suggests the model settings may be underfitting, or the signal is better captured by simpler structure.\n",
    "\n",
    "- **Gradient Boosting**  \n",
    "  Gradient Boosting performs close to OLS (second-best RMSE), but takes much longer to run.\n",
    "\n",
    "- **Decision Tree (CART)**  \n",
    "  CART performs better than LASSO and Random Forest, but worse than OLS and Gradient Boosting. This is expected since single trees can be unstable.\n",
    "\n",
    "Overall, the results show that simple models generalize well in this dataset.   \n",
    "OLS gives the best accuracy with low runtime, while boosting improves slightly but costs more time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a81151",
   "metadata": {},
   "source": [
    "##### Experience of Running Models on 'Live' Datasets\n",
    "\n",
    "While building the models, I faced runtime issues, mainly with the Random Forest model.\n",
    "\n",
    "**Key Learning Points**\n",
    "\n",
    "- Handling Runtime Issue in Original Model      \n",
    "    In **Part I**, the original Random Forest with `n_estimators = 500` took a very long time to run.   \n",
    "    So, I first reduced the number of trees to `200`, and this reduced runtime    \n",
    "\n",
    "- Applying Random Forest Model to Live Dataset  \n",
    "    I applied this model to the live Tokyo Q3 2025 dataset in Part II with `n_estimators = 200`     \n",
    "    The model still did not finish running, even after more than 6 minutes on live dataset.     \n",
    "    To keep the modelling process consistent and workable across all datasets, I went back to the original Random Forest model in Part I         \n",
    "    I reduced `n_estimators` even more to `100`.      \n",
    "\n",
    "    This allowed the model to run properly on both the original and live datasets.  \n",
    "\n",
    "- Balancing RMSE and Runtime        \n",
    "    As a result, the RMSE increased slightly, but the model became usable and comparable across datasets.   \n",
    "    Finding the balance between RMSE and runtime with trial and error was crucial for making my models workable.    \n",
    "\n",
    "- Experience with other models      \n",
    "    No such changes were needed for the other models.\n",
    "\n",
    "**Overall Learning**\n",
    "- Scalability       \n",
    "    This experience showed me the importance of considering runtime and scalability, not just predictive accuracy.      \n",
    "\n",
    "- Objective of Horserace Table      \n",
    "    It made me understand the need for the horserace table to compare models and their performance not only for base dataset, but also for 'live' datasets.  \n",
    "\n",
    "- Structure and Clear Documentation       \n",
    "    This trial-and-error process also taught me the value of a well-structured notebook, which made it easier to adjust individual models when needed.  \n",
    "    A lot less effort went into fixing individual models because I had a clear idea of how I wanted to structure my jupyter notebook.   \n",
    "    Clear documentation also proved to be extremely valuable to me here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
